[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cloud Architecure",
    "section": "",
    "text": "Introduction\nThe bwCloud is an ‚Äúinfrastructure-as-a-service‚Äù environment, specially developed and operated for research and teaching in Baden-W√ºrttemberg.\nWith the bwCloud, virtual servers or virtual machines (VMs) can be created, started and operated. These virtual machines include resources such as virtual CPUs (vCPUs), main memory (RAM), network access (IPv4 and IPv6 addresses) and storage space (storage) and do not differ in operation and administration from ‚Äúreal‚Äù physical machines.\nThis online book covers how to set up bwCloud."
  },
  {
    "objectID": "instance.html",
    "href": "instance.html",
    "title": "Virtual Machine",
    "section": "",
    "text": "tbd"
  },
  {
    "objectID": "instance-register.html",
    "href": "instance-register.html",
    "title": "1¬† Register for bwCloud SCOPE",
    "section": "",
    "text": "Registration is required to use the bwCloud infrastructure.\n\nVisit this site and choose your home organization and click on ‚ÄúProceed‚Äù or press enter.\nRegister for ‚ÄúbwCloud SCOPE‚Äù"
  },
  {
    "objectID": "key-pairs-create.html#what-is-ssh",
    "href": "key-pairs-create.html#what-is-ssh",
    "title": "2¬† Create SSH-Key",
    "section": "2.1 What is SSH?",
    "text": "2.1 What is SSH?\nSSH (Secure Shell) is a software package that enables secure system administration and file transfers over insecure networks. It is used in nearly every data center and in every large enterprise.\nAlthough SSH provides an encrypted connection, using passwords with SSH connections would leave our virtual machine (VM) in bwCloud vulnerable to attacks. Therefore, we connect to our VM over SSH using a public-private key pair, also known as SSH keys.\n\nThe public key is placed on your VM.\nThe private key remains on your local system. Protect this private key. Do not share it.\n\nWhen you use an SSH client to connect to your VM (which has the public key), the remote VM tests the client to make sure it has the correct private key. If the client has the private key, it‚Äôs granted access to the VM."
  },
  {
    "objectID": "key-pairs-create.html#create-ssh-keys-in-windows",
    "href": "key-pairs-create.html#create-ssh-keys-in-windows",
    "title": "2¬† Create SSH-Key",
    "section": "2.2 Create SSH-Keys in Windows",
    "text": "2.2 Create SSH-Keys in Windows\nFollow the instructions provided in bwCloud: SSH-Key Paar erzeugen"
  },
  {
    "objectID": "key-pairs-create.html#create-ssh-keys-in-macos",
    "href": "key-pairs-create.html#create-ssh-keys-in-macos",
    "title": "2¬† Create SSH-Key",
    "section": "2.3 Create SSH-Keys in MacOS",
    "text": "2.3 Create SSH-Keys in MacOS\n\n2.3.1 Create key\nOpen a terminal and run the following command:\nssh-keygen\nThis will output:\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/Users/username/.ssh/id_rsa):\nPress enter to save your keys to the default /Users/username/.ssh directory.\nAfter entering and confirming your password, you‚Äôll see something like the following:\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/Users/username/.ssh/id_rsa):\nEnter passphrase (empty for no passphrase):\nEnter same passphrase again:\nYour identification has been saved in /Users/username/.ssh/id_rsa\nYour public key has been saved in /Users/username/.ssh/id_rsa.pub\nThe key fingerprint is:\nSHA256:BOJAxs0Rkhusd9Hq/xdqWDnfd1cdxN5Uk+hD2gNwNLA1HvUM username@somename.local\nThe key's randomart image is:\n+---[RSA 3072]----+\n| .o*O ..D.BB+...o|\n|  .*. .  +o+=E...|\n|   ..        ..oo|\n|    . ..    oo o=|\n|   . . .S     o +|\n|           . .  .|\n|   ..o. . D.     |\n|   .+. .   XC    |\n|  .o.o.   L.     |\n+----[SHA256]-----+"
  },
  {
    "objectID": "key-pairs-create.html#set-permissions",
    "href": "key-pairs-create.html#set-permissions",
    "title": "2¬† Create SSH-Key",
    "section": "2.4 Set permissions",
    "text": "2.4 Set permissions\nNext, we use chmod to change permissions (otherwise, bwCloud will refuse the connection).\n\n\n\n\n\n\nIn Unix and Unix-like operating systems, chmod is the command and system call used to change the access permissions of files and directories. The name chmod was chosen as an abbreviation of change mode.\n\n\n\nChmod 700 sets folder permissions so that only the owner can read, write and execute files in this folder:\nchmod 700 .ssh\nPermissions of 600 mean that the owner has full read and write access to the file, while no other user can access the file:\nchmod 600 .ssh/id_rsa"
  },
  {
    "objectID": "key-pairs-create.html#mac-finder",
    "href": "key-pairs-create.html#mac-finder",
    "title": "2¬† Create SSH-Key",
    "section": "2.5 Mac Finder",
    "text": "2.5 Mac Finder\n\nOpen Finder and navigate to your/Users/username/\n\n\n\n\n\n\n\nHow to show your home folder in Finder\n\n\n\n\n\nIf you don‚Äôt find your home: In Finder, click on the menue and choose: Finder &gt; Preference &gt; Sidebar &gt; Show these items in the sidebar and checkmark the box beside the home icon.\n\n\n\n\nNow press the Command + Shift + . (period) keys at the same time. The hidden files will show up as translucent in your folder.\nOpen the folder .ssh.\nYou should see your public SSH key (id_rsa.pub) and private SSH key (id_rsa)"
  },
  {
    "objectID": "key-pairs-create.html#import-public-key",
    "href": "key-pairs-create.html#import-public-key",
    "title": "2¬† Create SSH-Key",
    "section": "2.6 Import public key",
    "text": "2.6 Import public key\n\nOpen your bwCloud Dashboard\nNavigate to Key Pairs in the left side menue.\nClick on Import Public Key\nProvide a Key Name and choose Key Type SSH Key.\nNow open your public key id_rsa.pub in a code editor like VS Code and copy and paste the content into Public Key"
  },
  {
    "objectID": "instance-create.html#details",
    "href": "instance-create.html#details",
    "title": "3¬† Create a launch instance",
    "section": "3.1 Details",
    "text": "3.1 Details\n\n\nProvide the instance name. We choose: bwcloud\nProvide a description for the instance, e.g.¬†bwCloud virtual machine\nChoose count 1"
  },
  {
    "objectID": "instance-create.html#source",
    "href": "instance-create.html#source",
    "title": "3¬† Create a launch instance",
    "section": "3.2 Source",
    "text": "3.2 Source\n\nInstance source is the template used to create an instance.\n\nChoose Ubuntu 22.04 (click on the arrow at the right)"
  },
  {
    "objectID": "instance-create.html#flavor",
    "href": "instance-create.html#flavor",
    "title": "3¬† Create a launch instance",
    "section": "3.3 Flavor",
    "text": "3.3 Flavor\n\nFlavors manage the sizing for the compute, memory and storage capacity of the instance. We use m1.nano.\n\nChoose m1.nano (click on the arrow at the right)"
  },
  {
    "objectID": "instance-create.html#networks",
    "href": "instance-create.html#networks",
    "title": "3¬† Create a launch instance",
    "section": "3.4 Networks",
    "text": "3.4 Networks\n\nNetworks provide the communication channels for instances in the cloud.\n\nWe use public-belwue"
  },
  {
    "objectID": "instance-create.html#network-ports",
    "href": "instance-create.html#network-ports",
    "title": "3¬† Create a launch instance",
    "section": "3.5 Network Ports",
    "text": "3.5 Network Ports\nPorts provide extra communication channels to your instances. You can select ports instead of networks or a mix of both.\n\nWe dont use network ports"
  },
  {
    "objectID": "instance-create.html#security-groups",
    "href": "instance-create.html#security-groups",
    "title": "3¬† Create a launch instance",
    "section": "3.6 Security Groups",
    "text": "3.6 Security Groups\n\nChoose default and your custom security groups\nFollow this bwCloud-tutorial to open a port."
  },
  {
    "objectID": "instance-create.html#key-pair",
    "href": "instance-create.html#key-pair",
    "title": "3¬† Create a launch instance",
    "section": "3.7 Key Pair",
    "text": "3.7 Key Pair\n\n\nSelect the key pair from step create-key-pairs.\nHere, it‚Äôs called ‚Äúid-rsa-pub‚Äù"
  },
  {
    "objectID": "instance-create.html#launch-instance",
    "href": "instance-create.html#launch-instance",
    "title": "3¬† Create a launch instance",
    "section": "3.8 Launch Instance",
    "text": "3.8 Launch Instance\n\n\nWe are done and you can click on ‚ÄúLaunch Instance‚Äù."
  },
  {
    "objectID": "instance-create.html#dashboard",
    "href": "instance-create.html#dashboard",
    "title": "3¬† Create a launch instance",
    "section": "3.9 Dashboard",
    "text": "3.9 Dashboard\n\n\nRefresh your browser\nYou should see your newly created instance in your dashboard.\nClick on the instance name to see more details"
  },
  {
    "objectID": "instance-login.html#terminal",
    "href": "instance-login.html#terminal",
    "title": "4¬† Log into instance",
    "section": "4.1 Terminal",
    "text": "4.1 Terminal\n\n4.1.1 Mac\nChange the IP adress and enter\nssh -i .ssh/id_rsa ubuntu@193.196.52.36\nIf you are asked: Are you sure you want to continue connecting (yes/no/[fingerprint])?\nEnter ‚Äúyes‚Äù.\nEnter passphrase for key ‚Äò.ssh/id_rsa‚Äô:\nProvide your password"
  },
  {
    "objectID": "vs-code-ssh.html#prerequisites",
    "href": "vs-code-ssh.html#prerequisites",
    "title": "5¬† Visual Studio Code & SSH",
    "section": "5.1 Prerequisites",
    "text": "5.1 Prerequisites\nTo get started, you need to have done the following steps:\n\nIf you use Windows, you need to install an OpenSSH compatible SSH client (PuTTY is not supported)\nInstall Visual Studio Code\nInstall all necessary local VS Code extensions by importing this profile remote-ssh(choose ‚ÄúImport Profile in Visual Studio Code‚Äù)"
  },
  {
    "objectID": "vs-code-ssh.html#connect-using-ssh",
    "href": "vs-code-ssh.html#connect-using-ssh",
    "title": "5¬† Visual Studio Code & SSH",
    "section": "5.2 Connect using SSH",
    "text": "5.2 Connect using SSH\n\nWithin VS Code, you should see a status bar item at the far left (at the bottom) in VS Code.\nThe Remote Status bar item can quickly show you in which context VS Code is running (local or remote) and clicking on the item will bring up the Remote - SSH command.\nChoose the ‚ÄúConnect to Host‚Ä¶‚Äù command in the Remote-SSH section and connect to the host by entering connection information for your VM in the following format (replace x with your IP): ubuntu@xxx.xxx.xx.xx\nIf propmted, enter your passphrase (SSH-key password) in VS Code.\nOpen VS Code‚Äôs integrated terminal (in the menue, select Terminal -&gt; new Terminal), to be able to work inside a bash shell."
  },
  {
    "objectID": "vs-code-ssh.html#install-extensions-on-ssh-host",
    "href": "vs-code-ssh.html#install-extensions-on-ssh-host",
    "title": "5¬† Visual Studio Code & SSH",
    "section": "5.3 Install extensions on SSH host",
    "text": "5.3 Install extensions on SSH host\nInstall all locally installed extensions on the SSH host:\n\nGo to the Extensions view\nUse the cloud button at the right of the ‚ÄúSSH: {Hostname}‚Äù‚Äù title bar.\nThis will display a dropdown where you can select which locally installed extensions to install on your SSH host (select all)."
  },
  {
    "objectID": "instance-storage-increase.html#increase-cloud-storage",
    "href": "instance-storage-increase.html#increase-cloud-storage",
    "title": "6¬† Increase Cloud Storage",
    "section": "6.1 Increase Cloud Storage",
    "text": "6.1 Increase Cloud Storage\n\n6.1.1 Select Volumes\n\n\nLog in to bwCloud Dashboard\nClick on ‚ÄúVolumes‚Äù below the ‚ÄúProject‚Äù tab\n\n\n\n\n6.1.2 Choose ‚ÄúCreate Volume‚Äù\n\n\nAn overview of the volumes you have created so far is displayed. To create a new volume, click on Create Volume\n\n\n\n6.1.3 Create Volume in dialogue\n\n\nA dialogue opens. Fill in the fields:\n\n\nVolume name: storage\nSize: 40 GiB\n\n\nThen click on Create Volume.\n\n\n\n6.1.4 Attach the volume\n\nIn order for a volume to be used by a virtual machine, it must be added (‚Äúattached‚Äù) to a VM.\n\nIn the table row of our new volume ‚Äústorage‚Äù, select the subitem ‚ÄúManage Attachments‚Äù in the context menu at the right end of the row and click on the entry.\n\n\n\n6.1.5 Attach volumes\n\n\nA dialogue opens: In the dialogue, select the desired virtual machine (‚ÄúbwCloud‚Äù) and click on ‚ÄúAttach Volume‚Äù.\nThe table updates and the path under which the new volume can be reached from within the virtual machine appears in the ‚ÄúAttached To field‚Äù:\n\n/dev/vdb on bwCloud"
  },
  {
    "objectID": "instance-storage-increase.html#mount-volume-in-vm",
    "href": "instance-storage-increase.html#mount-volume-in-vm",
    "title": "6¬† Increase Cloud Storage",
    "section": "6.2 Mount volume in VM",
    "text": "6.2 Mount volume in VM\nIn Linux, the process of attaching a filesystem to a particular point in the directory tree is called mounting. This allows you to access the files and directories on the filesystem as if they were part of the filesystem on which you are currently working.\n\n6.2.1 Log in your VM\n\nConnect to your virtual machine with VS Code remote connection (or your terminal)\n\n\n\n6.2.2 Find volumne\n\nEnter the follwing command in the integrated terminal to find your volume (i.e.¬†disk) using:\n\nsudo fdisk -l\nThe output should include an entry like the following:\n\nDisk /dev/vdb: 40 GiB, 42949672960 bytes, 83886080 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\n\n\n6.2.3 Partitioning\nNext, we need to partition our volume.\n\nThis command will create a GPT (GUID Partition Table), which is a standard for the layout of the partition table on a physical storage device:\n\nsudo parted /dev/vdb mklabel gpt\nThis will output: ‚ÄúWarning: The existing disk label on /dev/vdb will be destroyed and all data on this disk will be lost. Do you want to continue?‚Äù\n\nType: Yes\nWithin the partition environment, you can also set the size of the partition. In our case, we set the upper bound to 100%:\n\nsudo parted /dev/vdb mkpart primary ext4 0% 100%\n\n\n6.2.4 Format partition\nWe want to format the partition with the ext4 filesystem. ext4 stands for ‚Äúextended file system version 4‚Äù, which is a popular filesystem used in Linux systems to store and organize files on a storage device, such as a hard drive or solid-state drive.\n\nFormat the partition:\n\nsudo mkfs.ext4 /dev/vdb\nThis will output: Found a gpt partition table in /dev/vdb Proceed anyway? (y,N)\n\nType: Yes\n\n\n\n6.2.5 Mounting\nBefore we mount the drive, we create a new directory in the /mnt/ directory where the drives are usually mounted in Ubuntu:\nsudo mkdir /mnt/vdb\nOnce the directory is created, you can mount the drive as follows:\nsudo mount /dev/vdb /mnt/vdb\nTo mount the drive permanently, we need to edit the file system table fstab. Therefore, we open the file with the text editor nano:\nsudo nano /etc/fstab\nNow, add the following content at the end of the file:\n/dev/vdb    /mnt/vdb     ext4      defaults        0             0\nIt means that the partition located at /dev/vdb will be mounted to /mnt/vdb using the file system ext4, with default mount options and no dumping and no error-checking enabled.\nNext, press\n\nCtrl+O and confirm with enter to save the modifications you‚Äôve made to the file\nCtrl+X to close nano.\n\nTo check if everything worked fine, we use sudo mount to list all mounted drives and combine it with grep vdb, which only returns our volume vdb:\nsudo mount | grep vdb\nThis should output something like:\n/dev/vdb on /mnt/vdb type ext4 (rw,relatime)\nYou can change directory into your new volume and use it later to create new directories and store data in it:\ncd /mnt/vdb"
  },
  {
    "objectID": "instance-storage-increase.html#change-permissions",
    "href": "instance-storage-increase.html#change-permissions",
    "title": "6¬† Increase Cloud Storage",
    "section": "6.3 Change permissions",
    "text": "6.3 Change permissions\nLet‚Äôs change the file permissions for all the contents in the /mnt/vdb directory so we can read, write and execute files within this directory. In particular, this will allow us to modify files using VS Code without encountering a ‚Äúpermission denied‚Äù error.\n\nTo change the permissions of all files and directories within /mnt/vdb we we use the chmod command with the recursive (-R) option:\n\nsudo chmod -R 777 /mnt/vdb\nThis command will set the permissions to read (r), write (w), and execute (x) for the owner, group, and others on all files and directories within /mnt/vdb.\nHowever, please exercise caution when setting permissions to 777, as it grants full access to everyone, which may have security implications. Therefore, make sure to adjust the permissions as necessary based on your specific requirements and security considerations in your use cases."
  },
  {
    "objectID": "python.html",
    "href": "python.html",
    "title": "Programming toolkit",
    "section": "",
    "text": "tbd"
  },
  {
    "objectID": "python-miniconda-setup.html#installation-steps",
    "href": "python-miniconda-setup.html#installation-steps",
    "title": "7¬† Miniconda",
    "section": "7.1 Installation steps",
    "text": "7.1 Installation steps\nMiniconda is a free minimal installer for conda. It is a small, bootstrap version of Anaconda that includes only conda, Python, the packages they depend on, and a small number of other useful packages, including pip, zlib and a few others.\n\nThe following snippet will create a directory to install miniconda into:\n\nsudo mkdir /bin/miniconda3/\n\nDownload the latest Miniconda installer for Linux:\n\nsudo wget -P /bin/miniconda3/ https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n\nChange the directory to /bin/miniconda3/:\n\ncd /bin/miniconda3/\n\nMake the installer script executable:\n\nsudo chmod +x Miniconda3-latest-Linux-x86_64.sh\n\nRun the installer script with root permissions:\n\nsudo ./Miniconda3-latest-Linux-x86_64.sh\n\nThe installer will prompt you to accept the license agreement and select the installation directory. Press ‚ÄòENTER‚Äô to read the license and type ‚Äòyes‚Äô to accept it.\nWhen asked for the installation directory, provide this custom path:\n\n/home/ubuntu/miniconda3\n\nThe installer will install Miniconda and its dependencies. Once the installation is complete, it will ask if you want to initialize Miniconda3 by running conda init. Type ‚Äòyes‚Äô and press ‚ÄòENTER‚Äô\nNow we can remove the installer script\n\nsudo rm -rf /bin/miniconda3/miniconda.sh\n\nClose and reopen your terminal to activate the changes."
  },
  {
    "objectID": "python-miniconda-setup.html#start-jupyter-notebook-in-vs-code",
    "href": "python-miniconda-setup.html#start-jupyter-notebook-in-vs-code",
    "title": "7¬† Miniconda",
    "section": "7.2 Start Jupyter Notebook in VS Code",
    "text": "7.2 Start Jupyter Notebook in VS Code\nIn Visual Studio Code:\n\nCreate a Jupyter Notebook file\nNext, select a kernel using the ‚ÄúSelect Kernel‚Äù picker in the top right\n\n\n\nSelect Python Environments\nChoose the ‚Äúbase‚Äù environment\n\nIf you can‚Äôt see your base environment:\n\nShow command palette: Press cmd+shift+p (Mac) or strl+shift+p (Windows)\nSearch for `Python: Select Interpreter¬¥\nSelect + enter interpreter path\nChoose the interpreter ‚Äòbase‚Äô:conda"
  },
  {
    "objectID": "docker.html#what-is-docker",
    "href": "docker.html#what-is-docker",
    "title": "Docker",
    "section": "What is Docker?",
    "text": "What is Docker?\nDocker is an open-source platform that automates the deployment, scaling, and management of applications using containerization technology.\nIt enables developers to build, package, and deploy applications as lightweight, portable containers that can run consistently across various environments."
  },
  {
    "objectID": "docker.html#benefits-of-docker",
    "href": "docker.html#benefits-of-docker",
    "title": "Docker",
    "section": "Benefits of Docker",
    "text": "Benefits of Docker\n\nConsistent Environment\nDocker allows developers to create a consistent environment throughout the entire development and deployment lifecycle. By using containers, applications can be developed, tested, and deployed in the same environment, reducing the risk of inconsistencies and configuration issues.\n\n\nFast Deployment\nDocker containers are lightweight and start quickly, allowing for rapid deployment of applications. This is especially beneficial in environments where frequent updates or scaling are required.\n\n\nScalability\nDocker‚Äôs containerization technology enables easy horizontal scaling of applications. By running multiple instances of a container, you can distribute the load across these instances, providing better performance and availability.\n\n\nIsolation\nContainers in Docker are isolated from each other and the host system, ensuring that they do not interfere with each other. This isolation improves security and allows for better control over resources.\n\n\nVersion Control\nDocker images can be versioned, allowing you to easily roll back to previous versions or update to new ones as needed. This capability makes it simple to manage the lifecycle of your application.\n\n\nResource Efficiency\nDocker containers share the host system‚Äôs kernel, which means they use fewer resources than traditional virtual machines. This efficiency allows you to run more containers on a single host, reducing hardware and operational costs."
  },
  {
    "objectID": "docker.html#docker-architecture",
    "href": "docker.html#docker-architecture",
    "title": "Docker",
    "section": "Docker Architecture",
    "text": "Docker Architecture\nDocker follows a client-server model, which consists of the following components:\n\nDocker Client: The command-line interface or graphical user interface (GUI) used to interact with Docker.\nDocker Daemon: The background service that manages Docker objects, such as images, containers, networks, and volumes.\nDocker Registry: The centralized repository where Docker images are stored and distributed. Docker Hub is a popular public registry."
  },
  {
    "objectID": "docker.html#key-docker-components",
    "href": "docker.html#key-docker-components",
    "title": "Docker",
    "section": "Key Docker Components",
    "text": "Key Docker Components\n\nDockerfile\nA Dockerfile is a text file that contains instructions for building a Docker image. It defines the base image, application code, dependencies, and configuration settings needed to create a container.\n\n\nDocker Image\nA Docker image is a read-only template that contains the application and its dependencies. It is created by building a Dockerfile and can be stored in a Docker registry, such as Docker Hub, for easy distribution.\n\n\nDocker Container\nA Docker container is a running instance of a Docker image. Containers can be started, stopped, and managed using Docker commands.\n\n\nDocker Hub\nDocker Hub is a cloud-based registry service where you can share and manage Docker images. It enables you to store and distribute your images publicly or privately, making it easy to collaborate with others."
  },
  {
    "objectID": "docker.html#basic-docker-commands",
    "href": "docker.html#basic-docker-commands",
    "title": "Docker",
    "section": "Basic Docker Commands",
    "text": "Basic Docker Commands\n\ndocker build: Build Docker images from Dockerfiles\ndocker run: Run a Docker container from an image\ndocker ps: List running containers\ndocker images: List available images on the system\ndocker pull: Download an image from Docker Hub\ndocker push: Upload an image to Docker Hub\ndocker stop: Stop a running container"
  },
  {
    "objectID": "docker.html#conclusion",
    "href": "docker.html#conclusion",
    "title": "Docker",
    "section": "Conclusion",
    "text": "Conclusion\nDocker simplifies the deployment and management of applications by providing a consistent and portable environment using containerization technology. Its key components and basic commands allow developers to build, share, and run containers with ease, while its architecture ensures scalability, isolation, and resource efficiency."
  },
  {
    "objectID": "docker-setup.html#set-up-docker-repository",
    "href": "docker-setup.html#set-up-docker-repository",
    "title": "8¬† Docker set up",
    "section": "8.1 Set up Docker repository",
    "text": "8.1 Set up Docker repository\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\nUpdate the apt package index:\n\nsudo apt-get update\n\nInstall packages to allow apt to use a repository over HTTPS:\n\nsudo apt-get install \\\n    ca-certificates \\\n    curl \\\n    gnupg \\\n    lsb-release\n\nConfirm the installation with Y\nAdd Docker‚Äôs official GPG key:\n\nsudo mkdir -p /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n\nUse the following command to set up the repository:\n\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null"
  },
  {
    "objectID": "docker-setup.html#install-docker-engine",
    "href": "docker-setup.html#install-docker-engine",
    "title": "8¬† Docker set up",
    "section": "8.2 Install Docker Engine",
    "text": "8.2 Install Docker Engine\n\nAgain, update the apt package index:\n\nsudo apt-get update\n\nInstall Docker Engine, containerd, and Docker Compose:\n\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n\nPress Y to continue\nVerify that the Docker Engine installation is successful by running the hello-world image:\n\nsudo docker run hello-world\nThis command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\nGreat! You have now successfully installed and started Docker Engine."
  },
  {
    "objectID": "docker-location.html",
    "href": "docker-location.html",
    "title": "9¬† Change docker location",
    "section": "",
    "text": "The standard data directory used for docker is /var/lib/docker on our virtual machine. Since this directory will store a lot of data it can become quite large. Therefore, we move the docker data directory to our volumne mnt/vdb.\nHere are the steps to move the directory:\n\nStop docker daemon\n\nsudo systemctl stop docker\n\nCreate a new docker directory in /mnt/vdb:\n\nsudo mkdir -p /mnt/vdb/docker\n\nMake a copy of your current docker directory in the new location:\n\nsudo rsync -a /var/lib/docker/ /mnt/vdb/docker\n\nCreate a backup\n\nsudo mv /var/lib/docker /var/lib/docker-backup\n\nCreate a symbolic link (symlink):\n\nsudo ln -s /mnt/vdb/docker /var/lib/docker\n\nStart docker:\n\nsudo systemctl start docker\n\nCheck if the docker image ‚Äúhello-world‚Äù is still accessible:\n\nsudo docker ps -a\nYou can now remove your backup:\nsudo rm -rf /var/lib/docker-backup\nThat‚Äôs it!"
  },
  {
    "objectID": "docker-start-prerequisites.html#prerequisites",
    "href": "docker-start-prerequisites.html#prerequisites",
    "title": "10¬† Get started with Docker",
    "section": "10.1 Prerequisites",
    "text": "10.1 Prerequisites\nTo complete this guide, you‚Äôll need the following:\n\nDocker on your virtual machine in volume mnt/vdb.\nVisual Studio Code.\nA conceptual understanding of containers and images."
  },
  {
    "objectID": "docker-start-prerequisites.html#get-the-app",
    "href": "docker-start-prerequisites.html#get-the-app",
    "title": "10¬† Get started with Docker",
    "section": "10.2 Get the app",
    "text": "10.2 Get the app\nBefore you can run the application, you need to get the application source code onto your machine.\n\nChange directory into mnt/vdb\n\n cd /mnt/vdb\n\nClone the getting-started repository using the following command:\n\nsudo git clone https://github.com/docker/getting-started.git\nNext, we view the contents of the cloned repository in VS Code.\n\nNavigate to the VS code menue at the top and choose ‚ÄòFile‚Äô &gt; ‚ÄòOpen Folder‚Äô and insert: /mnt/vdb/getting-started/app (this will open a new window and you have to insert your SSH-key)\n\nInside the getting-started/app directory you should see package.json and two subdirectories (src and spec)."
  },
  {
    "objectID": "docker-start-containerize.html#create-dockerfile",
    "href": "docker-start-containerize.html#create-dockerfile",
    "title": "11¬† Containerize the application",
    "section": "11.1 Create Dockerfile",
    "text": "11.1 Create Dockerfile\nTo build a container image, you‚Äôll need to use a Dockerfile.\nA Dockerfile is simply a text-based file with no file extension that contains a script of instructions. Docker uses this script to build a container image.\n\nIn VS Code, open the integrated terminal (‚ÄúTerminal‚Äù &gt; ‚ÄúNew Terminal‚Äù).\n\n\n\nUse the following command to create an empty file named Dockerfile.\n\nsudo touch Dockerfile\n\n\nIn VS Code, open Dockerfile, add the following contents and save the file:\n\n# syntax=docker/dockerfile:1\n   \nFROM node:18-alpine\nWORKDIR /app\nCOPY . .\nRUN yarn install --production\nCMD [\"node\", \"src/index.js\"]\nEXPOSE 3000\nThis Dockerfile is used to create a Docker image for our Node.js application. Let‚Äôs go through each line and explain its purpose:\nFROM node:18-alpine\nThis line specifies the base image for the Docker image. It uses the node:18-alpine image, which is based on Alpine Linux (a lightweight Linux distribution) and includes Node.js version 18.\nWORKDIR /app\nThis line sets the working directory inside the Docker image to /app. Any subsequent commands will be executed in this directory.\nCOPY . .\nThis line copies the contents of the current directory (where the Dockerfile is located) into the /app directory of the Docker image. It includes all the files and directories required for the Node.js application.\nRUN yarn install --production\nThis line executes the command yarn install ‚Äìproduction within the Docker image. It installs the dependencies specified in the package.json file of the application. The ‚Äìproduction flag ensures that only production dependencies are installed, excluding any development-specific packages.\nCMD [\"node\", \"src/index.js\"]\nThis line specifies the command to run when the Docker container is started based on this image. It sets the entrypoint to node src/index.js, which means that the Node.js application‚Äôs entry file is src/index.js. This command will be executed when the container starts.\nEXPOSE 3000\nThis line informs Docker that the container will listen on port 3000. It does not publish the port to the host machine but rather serves as a documentation for developers or users who may run the container and need to know which port to access the application. In summary, this Dockerfile sets up a containerized environment for a Node.js application. It installs the production dependencies, specifies the entrypoint for the application, and indicates that it will listen on port 3000."
  },
  {
    "objectID": "docker-start-containerize.html#build-container-image",
    "href": "docker-start-containerize.html#build-container-image",
    "title": "11¬† Containerize the application",
    "section": "11.2 Build container image",
    "text": "11.2 Build container image\nBuild the container image using the following commands:\n\nBuild the container image using the following commands:\n\nsudo docker build -t getting-started .\nThe docker build command uses the Dockerfile to build a new container image. You might have noticed that Docker downloaded a lot of ‚Äúlayers‚Äù. This is because you instructed the builder that you wanted to start from the node:18-alpine image. But, since you didn‚Äôt have that on your machine, Docker needed to download the image.\nAfter Docker downloaded the image, the instructions from the Dockerfile copied in your application and used yarn to install your application‚Äôs dependencies. The CMD directive specifies the default command to run when starting a container from this image.\nFinally, the -t flag tags your image. Think of this simply as a human-readable name for the final image. Since you named the image getting-started, you can refer to that image when you run a container.\nThe . at the end of the docker build command tells Docker that it should look for the Dockerfile in the current directory."
  },
  {
    "objectID": "docker-start-containerize.html#start-app-container",
    "href": "docker-start-containerize.html#start-app-container",
    "title": "11¬† Containerize the application",
    "section": "11.3 Start app container",
    "text": "11.3 Start app container\nNow that you have an image, you can run the application in a container. To do so, you will use the docker run command.\n\nStart your container using the docker run command and specify the name of the image you just created:\n\nsudo docker run -dp 3000:3000 getting-started\nYou use the -d flag to run the new container in ‚Äúdetached‚Äù mode (in the background).\nYou also use the -p flag to create a mapping between the host‚Äôs port 3000 to the container‚Äôs port 3000. Without the port mapping, you wouldn‚Äôt be able to access the application."
  },
  {
    "objectID": "docker-start-containerize.html#forward-a-port",
    "href": "docker-start-containerize.html#forward-a-port",
    "title": "11¬† Containerize the application",
    "section": "11.4 Forward a port",
    "text": "11.4 Forward a port\n\nNext, we need to temporarily forward a new port for the duration of the session. Select ‚ÄúForward a Port‚Äù from the Command Palette (Windows: F1; Mac: ‚áß+‚åò+P) and insert the port number: 3000\nThis will open the ‚ÄúPORTS‚Äù view. In the column ‚ÄúLocal Address‚Äù, click on localhost:3000 and choose the globe üåê icon to open the web browser.\n\n\n\nThis should open your web browser to http://localhost:3000 and you should see your app."
  },
  {
    "objectID": "docker-start-containerize.html#test-your-app",
    "href": "docker-start-containerize.html#test-your-app",
    "title": "11¬† Containerize the application",
    "section": "11.5 Test your app",
    "text": "11.5 Test your app\n\nGo ahead and add an item or two and see that it works as you expect. You can mark items as complete and remove them. Your frontend is successfully storing items in the backend.\nAt this point, you should have a running todo list manager with a few items."
  },
  {
    "objectID": "docker-start-containerize.html#view-container",
    "href": "docker-start-containerize.html#view-container",
    "title": "11¬† Containerize the application",
    "section": "11.6 View container",
    "text": "11.6 View container\nIf you take a quick look at your containers, you should see at least one container running that is using the getting-started image and on port 3000.\n\nRun the following docker ps command in your terminal to list your containers.\n\nsudo docker ps\n\n11.6.1 Next steps\nIn the previous section, you learned the basics about creating a Dockerfile to build a container image. Once you built an image, you started a container and saw the running app.\nNext, you‚Äôre going to make a modification to your app and learn how to update your running application with a new image. Along the way, you‚Äôll learn a few other useful commands."
  },
  {
    "objectID": "docker-start-update.html#update-the-source-code",
    "href": "docker-start-update.html#update-the-source-code",
    "title": "12¬† Update application",
    "section": "12.1 Update the source code",
    "text": "12.1 Update the source code\nIn the steps below, you will change the ‚Äúempty text‚Äù when you don‚Äôt have any todo list items to ‚ÄúYou have no todo items yet! Add one above!‚Äù\n\nIn the src/static/js/app.js file, update line 56 to use the new empty text (replace the text marked as - with the new text marked with +). Dont forget to save the changes.\n\n\n...\n -                &lt;p className=\"text-center\"&gt;No items yet! Add one above!&lt;/p&gt;\n +                &lt;p className=\"text-center\"&gt;You have no todo items yet! Add one above!&lt;/p&gt;\n ..."
  },
  {
    "objectID": "docker-start-update.html#build-image",
    "href": "docker-start-update.html#build-image",
    "title": "12¬† Update application",
    "section": "12.2 Build image",
    "text": "12.2 Build image\n\nBuild your updated version of the image, using the same docker build command you used in part 2.\n\nsudo docker build -t getting-started .\n\nStart a new container using the updated code.\n\nsudo docker run -dp 3000:3000 getting-started\nYou probably saw an error like this (the IDs will be different):\ndocker: Error response from daemon: driver failed programming external connectivity on endpoint competent_shirley (b83e81e06e1ad74187ac3d7248be33a557820d35d597877985804eecf3bfba69): Bind for 0.0.0.0:3000 failed: port is already allocated.\nThe error occurred because you aren‚Äôt able to start the new container while your old container is still running.\nThe reason is that the old container is already using the host‚Äôs port 3000 and only one process on the machine (containers included) can listen to a specific port. To fix this, you need to remove the old container."
  },
  {
    "objectID": "docker-start-update.html#remove-old-container",
    "href": "docker-start-update.html#remove-old-container",
    "title": "12¬† Update application",
    "section": "12.3 Remove old container",
    "text": "12.3 Remove old container\nTo remove a container, you first need to stop it. Once it has stopped, you can remove it.\n\nGet the ID of the container by using the docker ps command.\n\nsudo docker ps\n\nUse the docker stop command to stop the container. Replace  with the ID from docker ps.\n\nsudo docker stop &lt;the-container-id&gt;\n\nOnce the container has stopped, you can remove it by using the docker rm command.\n\nsudo docker rm &lt;the-container-id&gt;\nNote: You can also stop and remove a container in a single command by adding the force flag to the docker rm command. For example: docker rm -f &lt;the-container-id&gt;"
  },
  {
    "objectID": "docker-start-update.html#start-the-updated-app-container",
    "href": "docker-start-update.html#start-the-updated-app-container",
    "title": "12¬† Update application",
    "section": "12.4 Start the updated app container",
    "text": "12.4 Start the updated app container\nNow, start your updated app using the docker run command.\nsudo docker run -dp 3000:3000 getting-started\nRefresh your browser on http://localhost:3000 and you should see your updated help text."
  },
  {
    "objectID": "docker-start-update.html#next-steps",
    "href": "docker-start-update.html#next-steps",
    "title": "12¬† Update application",
    "section": "12.5 Next steps",
    "text": "12.5 Next steps\nWhile you were able to build an update, there were two things you might have noticed:\nAll of the existing items in your todo list are gone! That‚Äôs not a very good app! You‚Äôll fix that shortly.\nThere were a lot of steps involved for such a small change. In an upcoming section, you‚Äôll learn how to see code updates without needing to rebuild and start a new container every time you make a change. Before talking about persistence, you‚Äôll see how to share these images with others."
  },
  {
    "objectID": "docker-start-share.html#create-a-docker-id",
    "href": "docker-start-share.html#create-a-docker-id",
    "title": "13¬† Share the application",
    "section": "13.1 Create a Docker ID",
    "text": "13.1 Create a Docker ID\nDocker ID: A Docker ID allows you to access Docker Hub which is the world‚Äôs largest library and community for container images.\n\nCreate a Docker ID for free if you don‚Äôt have one."
  },
  {
    "objectID": "docker-start-share.html#create-a-repo",
    "href": "docker-start-share.html#create-a-repo",
    "title": "13¬† Share the application",
    "section": "13.2 Create a repo",
    "text": "13.2 Create a repo\nTo push an image, you first need to create a repository on Docker Hub.\n\nSign up or Sign in to Docker Hub.\nSelect the Create Repository button.\nFor the repo name, use getting-started. Make sure the Visibility is Public.\n\n\n\nSelect the Create button."
  },
  {
    "objectID": "docker-start-share.html#push-the-image",
    "href": "docker-start-share.html#push-the-image",
    "title": "13¬† Share the application",
    "section": "13.3 Push the image",
    "text": "13.3 Push the image\n\nIn the command line, try running the push command you see on Docker Hub. Note that your command will be using your namespace, not kirenz.\n\nsudo docker push kirenz/getting-started\nThis sould output an error message like the following:\nThe push refers to repository [docker.io/kirenz/getting-started]\nAn image does not exist locally with the tag: kirenz/getting-started\nTo fix this, you need to ‚Äútag‚Äù your existing image you‚Äôve built to give it another name.\n\nLogin to the Docker Hub using the command\n\nsudo docker login -u YOUR-USER-NAME\n\nUse the docker tag command to give the getting-started image a new name. Be sure to swap out YOUR-USER-NAME with your Docker ID.\n\nsudo docker tag getting-started YOUR-USER-NAME/getting-started\nTo learn more about the docker tag command, see docker tag.\n\nNow try your push command again. If you‚Äôre copying the value from Docker Hub, you can drop the tagname portion, as you didn‚Äôt add a tag to the image name. If you don‚Äôt specify a tag, Docker will use a tag called latest.\n\nsudo docker push YOUR-USER-NAME/getting-started\n\n13.3.1 Run image\nNow that your image has been built and pushed into a registry, try running your app on a brand new instance that has never seen this container image. To do this, you will use Play with Docker\n\nOpen your browser to Play with Docker.\nSelect Login and then select docker from the drop-down list.\n\n\n\nOnce you‚Äôre logged in, select the ADD NEW INSTANCE option on the left side bar. If you don‚Äôt see it, make your browser a little wider. After a few seconds, a terminal window opens in your browser.\nIn the terminal, start your freshly pushed app:\n\ndocker run -dp 3000:3000 YOUR-USER-NAME/getting-started\nYou should see the image get pulled down and eventually start up.\n\nSelect on the 3000 badge when it comes up and you should see the app with your modifications. If the 3000 badge doesn‚Äôt show up, you can select the Open Port button and type in 3000.\n\n!"
  },
  {
    "objectID": "docker-start-share.html#next-steps",
    "href": "docker-start-share.html#next-steps",
    "title": "13¬† Share the application",
    "section": "13.4 Next steps",
    "text": "13.4 Next steps\nIn this section, you learned how to share your images by pushing them to a registry. You then went to a brand new instance and were able to run the freshly pushed image. This is quite common in CI pipelines, where the pipeline will create the image and push it to a registry and then the production environment can use the latest version of the image.\nNow you can circle back around to what you noticed at the end of the last section. As a reminder, you noticed that when you restarted the app, you lost all of your todo list items. That‚Äôs obviously not a great user experience, so next you‚Äôll learn how you can persist the data across restarts."
  }
]