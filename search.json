[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cloud Architecure",
    "section": "",
    "text": "Introduction\nThe bwCloud is an ‚Äúinfrastructure-as-a-service‚Äù environment, specially developed and operated for research and teaching in Baden-W√ºrttemberg.\nWith the bwCloud, virtual servers or virtual machines (VMs) can be created, started and operated. These virtual machines include resources such as virtual CPUs (vCPUs), main memory (RAM), network access (IPv4 and IPv6 addresses) and storage space (storage) and do not differ in operation and administration from ‚Äúreal‚Äù physical machines.\nThis online book covers how to set up bwCloud."
  },
  {
    "objectID": "instance.html",
    "href": "instance.html",
    "title": "Virtual Machine",
    "section": "",
    "text": "tbd"
  },
  {
    "objectID": "instance-register.html",
    "href": "instance-register.html",
    "title": "1¬† Register for bwCloud SCOPE",
    "section": "",
    "text": "Registration is required to use the bwCloud infrastructure.\n\nVisit this site and choose your home organization and click on ‚ÄúProceed‚Äù or press enter.\nRegister for ‚ÄúbwCloud SCOPE‚Äù"
  },
  {
    "objectID": "key-pairs-create.html#what-is-ssh",
    "href": "key-pairs-create.html#what-is-ssh",
    "title": "2¬† Create SSH-Key",
    "section": "2.1 What is SSH?",
    "text": "2.1 What is SSH?\nSSH (Secure Shell) is a software package that enables secure system administration and file transfers over insecure networks. It is used in nearly every data center and in every large enterprise.\nAlthough SSH provides an encrypted connection, using passwords with SSH connections would leave our virtual machine (VM) in bwCloud vulnerable to attacks. Therefore, we connect to our VM over SSH using a public-private key pair, also known as SSH keys.\n\nThe public key is placed on your VM.\nThe private key remains on your local system. Protect this private key. Do not share it.\n\nWhen you use an SSH client to connect to your VM (which has the public key), the remote VM tests the client to make sure it has the correct private key. If the client has the private key, it‚Äôs granted access to the VM."
  },
  {
    "objectID": "key-pairs-create.html#create-ssh-keys-in-windows",
    "href": "key-pairs-create.html#create-ssh-keys-in-windows",
    "title": "2¬† Create SSH-Key",
    "section": "2.2 Create SSH-Keys in Windows",
    "text": "2.2 Create SSH-Keys in Windows\nFollow the instructions provided in bwCloud: SSH-Key Paar erzeugen"
  },
  {
    "objectID": "key-pairs-create.html#create-ssh-keys-in-macos",
    "href": "key-pairs-create.html#create-ssh-keys-in-macos",
    "title": "2¬† Create SSH-Key",
    "section": "2.3 Create SSH-Keys in MacOS",
    "text": "2.3 Create SSH-Keys in MacOS\n\n2.3.1 Create key\nOpen a terminal and run the following command:\nssh-keygen\nThis will output:\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/Users/username/.ssh/id_rsa):\nPress enter to save your keys to the default /Users/username/.ssh directory.\nAfter entering and confirming your password, you‚Äôll see something like the following:\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/Users/username/.ssh/id_rsa):\nEnter passphrase (empty for no passphrase):\nEnter same passphrase again:\nYour identification has been saved in /Users/username/.ssh/id_rsa\nYour public key has been saved in /Users/username/.ssh/id_rsa.pub\nThe key fingerprint is:\nSHA256:BOJAxs0Rkhusd9Hq/xdqWDnfd1cdxN5Uk+hD2gNwNLA1HvUM username@somename.local\nThe key's randomart image is:\n+---[RSA 3072]----+\n| .o*O ..D.BB+...o|\n|  .*. .  +o+=E...|\n|   ..        ..oo|\n|    . ..    oo o=|\n|   . . .S     o +|\n|           . .  .|\n|   ..o. . D.     |\n|   .+. .   XC    |\n|  .o.o.   L.     |\n+----[SHA256]-----+"
  },
  {
    "objectID": "key-pairs-create.html#set-permissions",
    "href": "key-pairs-create.html#set-permissions",
    "title": "2¬† Create SSH-Key",
    "section": "2.4 Set permissions",
    "text": "2.4 Set permissions\nNext, we use chmod to change permissions (otherwise, bwCloud will refuse the connection).\n\n\n\n\n\n\nIn Unix and Unix-like operating systems, chmod is the command and system call used to change the access permissions of files and directories. The name chmod was chosen as an abbreviation of change mode.\n\n\n\nChmod 700 sets folder permissions so that only the owner can read, write and execute files in this folder:\nchmod 700 .ssh\nPermissions of 600 mean that the owner has full read and write access to the file, while no other user can access the file:\nchmod 600 .ssh/id_rsa"
  },
  {
    "objectID": "key-pairs-create.html#mac-finder",
    "href": "key-pairs-create.html#mac-finder",
    "title": "2¬† Create SSH-Key",
    "section": "2.5 Mac Finder",
    "text": "2.5 Mac Finder\n\nOpen Finder and navigate to your/Users/username/\n\n\n\n\n\n\n\nHow to show your home folder in Finder\n\n\n\n\n\nIf you don‚Äôt find your home: In Finder, click on the menue and choose: Finder &gt; Preference &gt; Sidebar &gt; Show these items in the sidebar and checkmark the box beside the home icon.\n\n\n\n\nNow press the Command + Shift + . (period) keys at the same time. The hidden files will show up as translucent in your folder.\nOpen the folder .ssh.\nYou should see your public SSH key (id_rsa.pub) and private SSH key (id_rsa)"
  },
  {
    "objectID": "key-pairs-create.html#import-public-key",
    "href": "key-pairs-create.html#import-public-key",
    "title": "2¬† Create SSH-Key",
    "section": "2.6 Import public key",
    "text": "2.6 Import public key\n\nOpen your bwCloud Dashboard\nNavigate to Key Pairs in the left side menue.\nClick on Import Public Key\nProvide a Key Name and choose Key Type SSH Key.\nNow open your public key id_rsa.pub in a code editor like VS Code and copy and paste the content into Public Key"
  },
  {
    "objectID": "instance-create.html#details",
    "href": "instance-create.html#details",
    "title": "3¬† Create a launch instance",
    "section": "3.1 Details",
    "text": "3.1 Details\n\n\nProvide the instance name. We choose: bwcloud\nProvide a description for the instance, e.g.¬†bwCloud virtual machine\nChoose count 1"
  },
  {
    "objectID": "instance-create.html#source",
    "href": "instance-create.html#source",
    "title": "3¬† Create a launch instance",
    "section": "3.2 Source",
    "text": "3.2 Source\n\nInstance source is the template used to create an instance.\n\nChoose Ubuntu 22.04 (click on the arrow at the right)"
  },
  {
    "objectID": "instance-create.html#flavor",
    "href": "instance-create.html#flavor",
    "title": "3¬† Create a launch instance",
    "section": "3.3 Flavor",
    "text": "3.3 Flavor\n\nFlavors manage the sizing for the compute, memory and storage capacity of the instance. We use m1.nano.\n\nChoose m1.nano (click on the arrow at the right)"
  },
  {
    "objectID": "instance-create.html#networks",
    "href": "instance-create.html#networks",
    "title": "3¬† Create a launch instance",
    "section": "3.4 Networks",
    "text": "3.4 Networks\n\nNetworks provide the communication channels for instances in the cloud.\n\nWe use public-belwue"
  },
  {
    "objectID": "instance-create.html#network-ports",
    "href": "instance-create.html#network-ports",
    "title": "3¬† Create a launch instance",
    "section": "3.5 Network Ports",
    "text": "3.5 Network Ports\nPorts provide extra communication channels to your instances. You can select ports instead of networks or a mix of both.\n\nWe dont use network ports"
  },
  {
    "objectID": "instance-create.html#security-groups",
    "href": "instance-create.html#security-groups",
    "title": "3¬† Create a launch instance",
    "section": "3.6 Security Groups",
    "text": "3.6 Security Groups\n\nChoose default and your custom security groups\nFollow this bwCloud-tutorial to open a port."
  },
  {
    "objectID": "instance-create.html#key-pair",
    "href": "instance-create.html#key-pair",
    "title": "3¬† Create a launch instance",
    "section": "3.7 Key Pair",
    "text": "3.7 Key Pair\n\n\nSelect the key pair from step create-key-pairs.\nHere, it‚Äôs called ‚Äúid-rsa-pub‚Äù"
  },
  {
    "objectID": "instance-create.html#launch-instance",
    "href": "instance-create.html#launch-instance",
    "title": "3¬† Create a launch instance",
    "section": "3.8 Launch Instance",
    "text": "3.8 Launch Instance\n\n\nWe are done and you can click on ‚ÄúLaunch Instance‚Äù."
  },
  {
    "objectID": "instance-create.html#dashboard",
    "href": "instance-create.html#dashboard",
    "title": "3¬† Create a launch instance",
    "section": "3.9 Dashboard",
    "text": "3.9 Dashboard\n\n\nRefresh your browser\nYou should see your newly created instance in your dashboard.\nClick on the instance name to see more details"
  },
  {
    "objectID": "instance-login.html#terminal",
    "href": "instance-login.html#terminal",
    "title": "4¬† Log into instance",
    "section": "4.1 Terminal",
    "text": "4.1 Terminal\n\n4.1.1 Mac\nChange the IP adress and enter\nssh -i .ssh/id_rsa ubuntu@193.196.52.36\nIf you are asked: Are you sure you want to continue connecting (yes/no/[fingerprint])?\nEnter ‚Äúyes‚Äù.\nEnter passphrase for key ‚Äò.ssh/id_rsa‚Äô:\nProvide your password"
  },
  {
    "objectID": "vs-code-ssh.html#prerequisites",
    "href": "vs-code-ssh.html#prerequisites",
    "title": "5¬† Visual Studio Code & SSH",
    "section": "5.1 Prerequisites",
    "text": "5.1 Prerequisites\nTo get started, you need to have done the following steps:\n\nIf you use Windows, you need to install an OpenSSH compatible SSH client (PuTTY is not supported)\nInstall Visual Studio Code\nInstall all necessary local VS Code extensions by importing this profile remote-ssh(choose ‚ÄúImport Profile in Visual Studio Code‚Äù)"
  },
  {
    "objectID": "vs-code-ssh.html#connect-using-ssh",
    "href": "vs-code-ssh.html#connect-using-ssh",
    "title": "5¬† Visual Studio Code & SSH",
    "section": "5.2 Connect using SSH",
    "text": "5.2 Connect using SSH\n\nWithin VS Code, you should see a status bar item at the far left (at the bottom) in VS Code.\nThe Remote Status bar item can quickly show you in which context VS Code is running (local or remote) and clicking on the item will bring up the Remote - SSH command.\nChoose the ‚ÄúConnect to Host‚Ä¶‚Äù command in the Remote-SSH section and connect to the host by entering connection information for your VM in the following format (replace x with your IP): ubuntu@xxx.xxx.xx.xx\nIf propmted, enter your passphrase (SSH-key password) in VS Code.\nOpen VS Code‚Äôs integrated terminal (in the menue, select Terminal -&gt; new Terminal), to be able to work inside a bash shell."
  },
  {
    "objectID": "vs-code-ssh.html#install-extensions-on-ssh-host",
    "href": "vs-code-ssh.html#install-extensions-on-ssh-host",
    "title": "5¬† Visual Studio Code & SSH",
    "section": "5.3 Install extensions on SSH host",
    "text": "5.3 Install extensions on SSH host\nInstall all locally installed extensions on the SSH host:\n\nGo to the Extensions view\nUse the cloud button at the right of the ‚ÄúSSH: {Hostname}‚Äù‚Äù title bar.\nThis will display a dropdown where you can select which locally installed extensions to install on your SSH host (select all)."
  },
  {
    "objectID": "instance-storage-increase.html#increase-cloud-storage",
    "href": "instance-storage-increase.html#increase-cloud-storage",
    "title": "6¬† Increase Cloud Storage",
    "section": "6.1 Increase Cloud Storage",
    "text": "6.1 Increase Cloud Storage\n\n6.1.1 Select Volumes\n\n\nLog in to bwCloud Dashboard\nClick on ‚ÄúVolumes‚Äù below the ‚ÄúProject‚Äù tab\n\n\n\n\n6.1.2 Choose ‚ÄúCreate Volume‚Äù\n\n\nAn overview of the volumes you have created so far is displayed. To create a new volume, click on Create Volume\n\n\n\n6.1.3 Create Volume in dialogue\n\n\nA dialogue opens. Fill in the fields:\n\n\nVolume name: storage\nSize: 40 GiB\n\n\nThen click on Create Volume.\n\n\n\n6.1.4 Attach the volume\n\nIn order for a volume to be used by a virtual machine, it must be added (‚Äúattached‚Äù) to a VM.\n\nIn the table row of our new volume ‚Äústorage‚Äù, select the subitem ‚ÄúManage Attachments‚Äù in the context menu at the right end of the row and click on the entry.\n\n\n\n6.1.5 Attach volumes\n\n\nA dialogue opens: In the dialogue, select the desired virtual machine (‚ÄúbwCloud‚Äù) and click on ‚ÄúAttach Volume‚Äù.\nThe table updates and the path under which the new volume can be reached from within the virtual machine appears in the ‚ÄúAttached To field‚Äù:\n\n/dev/vdb on bwCloud"
  },
  {
    "objectID": "instance-storage-increase.html#mount-volume-in-vm",
    "href": "instance-storage-increase.html#mount-volume-in-vm",
    "title": "6¬† Increase Cloud Storage",
    "section": "6.2 Mount volume in VM",
    "text": "6.2 Mount volume in VM\nIn Linux, the process of attaching a filesystem to a particular point in the directory tree is called mounting. This allows you to access the files and directories on the filesystem as if they were part of the filesystem on which you are currently working.\n\n6.2.1 Log in your VM\n\nConnect to your virtual machine with VS Code remote connection (or your terminal)\n\n\n\n6.2.2 Find volumne\n\nEnter the follwing command in the integrated terminal to find your volume (i.e.¬†disk) using:\n\nsudo fdisk -l\nThe output should include an entry like the following:\n\nDisk /dev/vdb: 40 GiB, 42949672960 bytes, 83886080 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\n\n\n6.2.3 Partitioning\nNext, we need to partition our volume.\n\nThis command will create a GPT (GUID Partition Table), which is a standard for the layout of the partition table on a physical storage device:\n\nsudo parted /dev/vdb mklabel gpt\nThis will output: ‚ÄúWarning: The existing disk label on /dev/vdb will be destroyed and all data on this disk will be lost. Do you want to continue?‚Äù\n\nType: Yes\nWithin the partition environment, you can also set the size of the partition. In our case, we set the upper bound to 100%:\n\nsudo parted /dev/vdb mkpart primary ext4 0% 100%\n\n\n6.2.4 Format partition\nWe want to format the partition with the ext4 filesystem. ext4 stands for ‚Äúextended file system version 4‚Äù, which is a popular filesystem used in Linux systems to store and organize files on a storage device, such as a hard drive or solid-state drive.\n\nFormat the partition:\n\nsudo mkfs.ext4 /dev/vdb\nThis will output: Found a gpt partition table in /dev/vdb Proceed anyway? (y,N)\n\nType: Yes\n\n\n\n6.2.5 Mounting\nBefore we mount the drive, we create a new directory in the /mnt/ directory where the drives are usually mounted in Ubuntu:\nsudo mkdir /mnt/vdb\nOnce the directory is created, you can mount the drive as follows:\nsudo mount /dev/vdb /mnt/vdb\nTo mount the drive permanently, we need to edit the file system table fstab. Therefore, we open the file with the text editor nano:\nsudo nano /etc/fstab\nNow, add the following content at the end of the file:\n/dev/vdb    /mnt/vdb     ext4      defaults        0             0\nIt means that the partition located at /dev/vdb will be mounted to /mnt/vdb using the file system ext4, with default mount options and no dumping and no error-checking enabled.\nNext, press\n\nCtrl+O and confirm with enter to save the modifications you‚Äôve made to the file\nCtrl+X to close nano.\n\nTo check if everything worked fine, we use sudo mount to list all mounted drives and combine it with grep vdb, which only returns our volume vdb:\nsudo mount | grep vdb\nThis should output something like:\n/dev/vdb on /mnt/vdb type ext4 (rw,relatime)\nYou can change directory into your new volume and use it later to create new directories and store data in it:\ncd /mnt/vdb"
  },
  {
    "objectID": "instance-storage-increase.html#change-permissions",
    "href": "instance-storage-increase.html#change-permissions",
    "title": "6¬† Increase Cloud Storage",
    "section": "6.3 Change permissions",
    "text": "6.3 Change permissions\nLet‚Äôs change the file permissions for all the contents in the /mnt/vdb directory so we can read, write and execute files within this directory. In particular, this will allow us to modify files using VS Code without encountering a ‚Äúpermission denied‚Äù error.\n\nTo change the permissions of all files and directories within /mnt/vdb we we use the chmod command with the recursive (-R) option:\n\nsudo chmod -R 777 /mnt/vdb\nThis command will set the permissions to read (r), write (w), and execute (x) for the owner, group, and others on all files and directories within /mnt/vdb.\nHowever, please exercise caution when setting permissions to 777, as it grants full access to everyone, which may have security implications. Therefore, make sure to adjust the permissions as necessary based on your specific requirements and security considerations in your use cases."
  },
  {
    "objectID": "python.html",
    "href": "python.html",
    "title": "Programming toolkit",
    "section": "",
    "text": "tbd"
  },
  {
    "objectID": "python-miniconda-setup.html#installation-steps",
    "href": "python-miniconda-setup.html#installation-steps",
    "title": "7¬† Miniconda",
    "section": "7.1 Installation steps",
    "text": "7.1 Installation steps\nMiniconda is a free minimal installer for conda. It is a small, bootstrap version of Anaconda that includes only conda, Python, the packages they depend on, and a small number of other useful packages, including pip, zlib and a few others.\n\nThe following snippet will create a directory to install miniconda into:\n\nsudo mkdir /bin/miniconda3/\n\nDownload the latest Miniconda installer for Linux:\n\nsudo wget -P /bin/miniconda3/ https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n\nChange the directory to /bin/miniconda3/:\n\ncd /bin/miniconda3/\n\nMake the installer script executable:\n\nsudo chmod +x Miniconda3-latest-Linux-x86_64.sh\n\nRun the installer script with root permissions:\n\nsudo ./Miniconda3-latest-Linux-x86_64.sh\n\nThe installer will prompt you to accept the license agreement and select the installation directory. Press ‚ÄòENTER‚Äô to read the license and type ‚Äòyes‚Äô to accept it.\nWhen asked for the installation directory, provide this custom path:\n\n/home/ubuntu/miniconda3\n\nThe installer will install Miniconda and its dependencies. Once the installation is complete, it will ask if you want to initialize Miniconda3 by running conda init. Type ‚Äòyes‚Äô and press ‚ÄòENTER‚Äô\nNow we can remove the installer script\n\nsudo rm -rf /bin/miniconda3/miniconda.sh\n\nClose and reopen your terminal to activate the changes."
  },
  {
    "objectID": "python-miniconda-setup.html#start-jupyter-notebook-in-vs-code",
    "href": "python-miniconda-setup.html#start-jupyter-notebook-in-vs-code",
    "title": "7¬† Miniconda",
    "section": "7.2 Start Jupyter Notebook in VS Code",
    "text": "7.2 Start Jupyter Notebook in VS Code\nIn Visual Studio Code:\n\nCreate a Jupyter Notebook file\nNext, select a kernel using the ‚ÄúSelect Kernel‚Äù picker in the top right\n\n\n\nSelect Python Environments\nChoose the ‚Äúbase‚Äù environment\n\nIf you can‚Äôt see your base environment:\n\nShow command palette: Press cmd+shift+p (Mac) or strl+shift+p (Windows)\nSearch for `Python: Select Interpreter¬¥\nSelect + enter interpreter path\nChoose the interpreter ‚Äòbase‚Äô:conda"
  },
  {
    "objectID": "docker.html#what-is-docker",
    "href": "docker.html#what-is-docker",
    "title": "Docker",
    "section": "What is Docker?",
    "text": "What is Docker?\nDocker is an open-source platform that automates the deployment, scaling, and management of applications using containerization technology.\nIt enables developers to build, package, and deploy applications as lightweight, portable containers that can run consistently across various environments."
  },
  {
    "objectID": "docker.html#benefits-of-docker",
    "href": "docker.html#benefits-of-docker",
    "title": "Docker",
    "section": "Benefits of Docker",
    "text": "Benefits of Docker\n\nConsistent Environment\nDocker allows developers to create a consistent environment throughout the entire development and deployment lifecycle. By using containers, applications can be developed, tested, and deployed in the same environment, reducing the risk of inconsistencies and configuration issues.\n\n\nFast Deployment\nDocker containers are lightweight and start quickly, allowing for rapid deployment of applications. This is especially beneficial in environments where frequent updates or scaling are required.\n\n\nScalability\nDocker‚Äôs containerization technology enables easy horizontal scaling of applications. By running multiple instances of a container, you can distribute the load across these instances, providing better performance and availability.\n\n\nIsolation\nContainers in Docker are isolated from each other and the host system, ensuring that they do not interfere with each other. This isolation improves security and allows for better control over resources.\n\n\nVersion Control\nDocker images can be versioned, allowing you to easily roll back to previous versions or update to new ones as needed. This capability makes it simple to manage the lifecycle of your application.\n\n\nResource Efficiency\nDocker containers share the host system‚Äôs kernel, which means they use fewer resources than traditional virtual machines. This efficiency allows you to run more containers on a single host, reducing hardware and operational costs."
  },
  {
    "objectID": "docker.html#docker-architecture",
    "href": "docker.html#docker-architecture",
    "title": "Docker",
    "section": "Docker Architecture",
    "text": "Docker Architecture\nDocker follows a client-server model, which consists of the following components:\n\nDocker Client: The command-line interface or graphical user interface (GUI) used to interact with Docker.\nDocker Daemon: The background service that manages Docker objects, such as images, containers, networks, and volumes.\nDocker Registry: The centralized repository where Docker images are stored and distributed. Docker Hub is a popular public registry."
  },
  {
    "objectID": "docker.html#key-docker-components",
    "href": "docker.html#key-docker-components",
    "title": "Docker",
    "section": "Key Docker Components",
    "text": "Key Docker Components\n\nDockerfile\nA Dockerfile is a text file that contains instructions for building a Docker image. It defines the base image, application code, dependencies, and configuration settings needed to create a container.\n\n\nDocker Image\nA Docker image is a read-only template that contains the application and its dependencies. It is created by building a Dockerfile and can be stored in a Docker registry, such as Docker Hub, for easy distribution.\n\n\nDocker Container\nA Docker container is a running instance of a Docker image. Containers can be started, stopped, and managed using Docker commands.\n\n\nDocker Hub\nDocker Hub is a cloud-based registry service where you can share and manage Docker images. It enables you to store and distribute your images publicly or privately, making it easy to collaborate with others."
  },
  {
    "objectID": "docker.html#basic-docker-commands",
    "href": "docker.html#basic-docker-commands",
    "title": "Docker",
    "section": "Basic Docker Commands",
    "text": "Basic Docker Commands\n\ndocker build: Build Docker images from Dockerfiles\ndocker run: Run a Docker container from an image\ndocker ps: List running containers\ndocker images: List available images on the system\ndocker pull: Download an image from Docker Hub\ndocker push: Upload an image to Docker Hub\ndocker stop: Stop a running container"
  },
  {
    "objectID": "docker.html#conclusion",
    "href": "docker.html#conclusion",
    "title": "Docker",
    "section": "Conclusion",
    "text": "Conclusion\nDocker simplifies the deployment and management of applications by providing a consistent and portable environment using containerization technology. Its key components and basic commands allow developers to build, share, and run containers with ease, while its architecture ensures scalability, isolation, and resource efficiency."
  },
  {
    "objectID": "docker-setup.html#set-up-docker-repository",
    "href": "docker-setup.html#set-up-docker-repository",
    "title": "8¬† Docker set up",
    "section": "8.1 Set up Docker repository",
    "text": "8.1 Set up Docker repository\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\nUpdate the apt package index:\n\nsudo apt-get update\n\nInstall packages to allow apt to use a repository over HTTPS:\n\nsudo apt-get install \\\n    ca-certificates \\\n    curl \\\n    gnupg \\\n    lsb-release\n\nConfirm the installation with Y\nAdd Docker‚Äôs official GPG key:\n\nsudo mkdir -p /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n\nUse the following command to set up the repository:\n\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null"
  },
  {
    "objectID": "docker-setup.html#install-docker-engine",
    "href": "docker-setup.html#install-docker-engine",
    "title": "8¬† Docker set up",
    "section": "8.2 Install Docker Engine",
    "text": "8.2 Install Docker Engine\n\nAgain, update the apt package index:\n\nsudo apt-get update\n\nInstall Docker Engine, containerd, and Docker Compose:\n\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n\nPress Y to continue\nVerify that the Docker Engine installation is successful by running the hello-world image:\n\nsudo docker run hello-world\nThis command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\nGreat! You have now successfully installed and started Docker Engine."
  },
  {
    "objectID": "docker-location.html",
    "href": "docker-location.html",
    "title": "9¬† Change docker location",
    "section": "",
    "text": "The standard data directory used for docker is /var/lib/docker on our virtual machine. Since this directory will store a lot of data it can become quite large. Therefore, we move the docker data directory to our volumne mnt/vdb.\nHere are the steps to move the directory:\n\nStop docker daemon\n\nsudo systemctl stop docker\n\nCreate a new docker directory in /mnt/vdb:\n\nsudo mkdir -p /mnt/vdb/docker\n\nMake a copy of your current docker directory in the new location:\n\nsudo rsync -a /var/lib/docker/ /mnt/vdb/docker\n\nCreate a backup\n\nsudo mv /var/lib/docker /var/lib/docker-backup\n\nCreate a symbolic link (symlink):\n\nsudo ln -s /mnt/vdb/docker /var/lib/docker\n\nStart docker:\n\nsudo systemctl start docker\n\nCheck if the docker image ‚Äúhello-world‚Äù is still accessible:\n\nsudo docker ps -a\nYou can now remove your backup:\nsudo rm -rf /var/lib/docker-backup\nThat‚Äôs it!"
  },
  {
    "objectID": "docker-start-prerequisites.html#what-is-a-container",
    "href": "docker-start-prerequisites.html#what-is-a-container",
    "title": "10¬† Get started with Docker",
    "section": "10.1 What is a container?",
    "text": "10.1 What is a container?\nSimply put, a container is a sandboxed process on your machine that is isolated from all other processes on the host machine. That isolation leverages kernel namespaces and cgroups, features that have been in Linux for a long time. Docker has worked to make these capabilities approachable and easy to use.\nTo summarize, a container:\n\nIs a runnable instance of an image. You can create, start, stop, move, or delete a container using the DockerAPI or CLI.\nCan be run on local machines, virtual machines or deployed to the cloud.\nIs portable (can be run on any OS).\nIs isolated from other containers and runs its own software, binaries, and configurations."
  },
  {
    "objectID": "docker-start-prerequisites.html#what-is-a-container-image",
    "href": "docker-start-prerequisites.html#what-is-a-container-image",
    "title": "10¬† Get started with Docker",
    "section": "10.2 What is a container image?",
    "text": "10.2 What is a container image?\nWhen running a container, it uses an isolated filesystem. This custom filesystem is provided by a container image. Since the image contains the container‚Äôs filesystem, it must contain everything needed to run an application - all dependencies, configurations, scripts, binaries, etc. The image also contains other configuration for the container, such as environment variables, a default command to run, and other metadata."
  },
  {
    "objectID": "docker-start-prerequisites.html#get-the-app",
    "href": "docker-start-prerequisites.html#get-the-app",
    "title": "10¬† Get started with Docker",
    "section": "10.3 Get the app",
    "text": "10.3 Get the app\nBefore you can run the application, you need to get the application source code onto your machine.\n\nChange directory into mnt/vdb\n\n cd /mnt/vdb\n\nClone the getting-started repository using the following command:\n\nsudo git clone https://github.com/docker/getting-started.git\nNow view the contents of the cloned repository in VS Code:\n\nNavigate to the VS code menue at the top and choose ‚ÄòFile‚Äô &gt; ‚ÄòOpen Folder‚Äô and insert: /mnt/vdb/getting-started/app (this will open a new window and you have to insert your SSH-key)\n\nInside the getting-started/app directory you should see package.json and two subdirectories (src and spec)."
  },
  {
    "objectID": "docker-start-prerequisites.html#next-steps",
    "href": "docker-start-prerequisites.html#next-steps",
    "title": "10¬† Get started with Docker",
    "section": "10.4 Next steps",
    "text": "10.4 Next steps\nFor the rest of this guide, you‚Äôll be working with a simple todo list manager that runs on Node.js. If you‚Äôre not familiar with Node.js, don‚Äôt worry. This guide doesn‚Äôt require any prior experience with JavaScript.\nNext, you‚Äôll learn hwo to containerize an application."
  },
  {
    "objectID": "docker-start-containerize.html#create-dockerfile",
    "href": "docker-start-containerize.html#create-dockerfile",
    "title": "11¬† Containerize the application",
    "section": "11.1 Create Dockerfile",
    "text": "11.1 Create Dockerfile\nTo build a container image, you‚Äôll need to use a Dockerfile.\nA Dockerfile is simply a text-based file with no file extension that contains a script of instructions. Docker uses this script to build a container image.\n\nIn VS Code, open the integrated terminal (‚ÄúTerminal‚Äù &gt; ‚ÄúNew Terminal‚Äù).\n\n\n\nUse the following command to create an empty file named Dockerfile.\n\nsudo touch Dockerfile\n\n\nIn VS Code, open Dockerfile, add the following contents and save the file:\n\n# syntax=docker/dockerfile:1\n   \nFROM node:18-alpine\nWORKDIR /app\nCOPY . .\nRUN yarn install --production\nCMD [\"node\", \"src/index.js\"]\nEXPOSE 3000\nThis Dockerfile is used to create a Docker image for our Node.js application. Let‚Äôs go through each line and explain its purpose:\nFROM node:18-alpine\nThis line specifies the base image for the Docker image. It uses the node:18-alpine image, which is based on Alpine Linux (a lightweight Linux distribution) and includes Node.js version 18.\nWORKDIR /app\nThis line sets the working directory inside the Docker image to /app. Any subsequent commands will be executed in this directory.\nCOPY . .\nThis line copies the contents of the current directory (where the Dockerfile is located) into the /app directory of the Docker image. It includes all the files and directories required for the Node.js application.\nRUN yarn install --production\nThis line executes the command yarn install ‚Äìproduction within the Docker image. It installs the dependencies specified in the package.json file of the application. The ‚Äìproduction flag ensures that only production dependencies are installed, excluding any development-specific packages.\nCMD [\"node\", \"src/index.js\"]\nThis line specifies the command to run when the Docker container is started based on this image. It sets the entrypoint to node src/index.js, which means that the Node.js application‚Äôs entry file is src/index.js. This command will be executed when the container starts.\nEXPOSE 3000\nThis line informs Docker that the container will listen on port 3000. It does not publish the port to the host machine but rather serves as a documentation for developers or users who may run the container and need to know which port to access the application. In summary, this Dockerfile sets up a containerized environment for a Node.js application. It installs the production dependencies, specifies the entrypoint for the application, and indicates that it will listen on port 3000."
  },
  {
    "objectID": "docker-start-containerize.html#build-container-image",
    "href": "docker-start-containerize.html#build-container-image",
    "title": "11¬† Containerize the application",
    "section": "11.2 Build container image",
    "text": "11.2 Build container image\nBuild the container image using the following commands:\n\nBuild the container image using the following commands:\n\nsudo docker build -t getting-started .\nThe docker build command uses the Dockerfile to build a new container image. You might have noticed that Docker downloaded a lot of ‚Äúlayers‚Äù. This is because you instructed the builder that you wanted to start from the node:18-alpine image. But, since you didn‚Äôt have that on your machine, Docker needed to download the image.\nAfter Docker downloaded the image, the instructions from the Dockerfile copied in your application and used yarn to install your application‚Äôs dependencies. The CMD directive specifies the default command to run when starting a container from this image.\nFinally, the -t flag tags your image. Think of this simply as a human-readable name for the final image. Since you named the image getting-started, you can refer to that image when you run a container.\nThe . at the end of the docker build command tells Docker that it should look for the Dockerfile in the current directory."
  },
  {
    "objectID": "docker-start-containerize.html#start-app-container",
    "href": "docker-start-containerize.html#start-app-container",
    "title": "11¬† Containerize the application",
    "section": "11.3 Start app container",
    "text": "11.3 Start app container\nNow that you have an image, you can run the application in a container. To do so, you will use the docker run command.\n\nStart your container using the docker run command and specify the name of the image you just created:\n\nsudo docker run -dp 3000:3000 getting-started\nYou use the -d flag to run the new container in ‚Äúdetached‚Äù mode (in the background).\nYou also use the -p flag to create a mapping between the host‚Äôs port 3000 to the container‚Äôs port 3000. Without the port mapping, you wouldn‚Äôt be able to access the application."
  },
  {
    "objectID": "docker-start-containerize.html#forward-a-port",
    "href": "docker-start-containerize.html#forward-a-port",
    "title": "11¬† Containerize the application",
    "section": "11.4 Forward a port",
    "text": "11.4 Forward a port\n\nNext, we need to temporarily forward a new port for the duration of the session. Select ‚ÄúForward a Port‚Äù from the Command Palette (Windows: F1; Mac: ‚áß+‚åò+P) and insert the port number: 3000\nThis will open the ‚ÄúPORTS‚Äù view. In the column ‚ÄúLocal Address‚Äù, click on localhost:3000 and choose the globe üåê icon to open the web browser.\n\n\n\nThis should open your web browser to http://localhost:3000 and you should see your app."
  },
  {
    "objectID": "docker-start-containerize.html#test-your-app",
    "href": "docker-start-containerize.html#test-your-app",
    "title": "11¬† Containerize the application",
    "section": "11.5 Test your app",
    "text": "11.5 Test your app\n\nGo ahead and add an item or two and see that it works as you expect. You can mark items as complete and remove them. Your frontend is successfully storing items in the backend.\nAt this point, you should have a running todo list manager with a few items."
  },
  {
    "objectID": "docker-start-containerize.html#view-container",
    "href": "docker-start-containerize.html#view-container",
    "title": "11¬† Containerize the application",
    "section": "11.6 View container",
    "text": "11.6 View container\nIf you take a quick look at your containers, you should see at least one container running that is using the getting-started image and on port 3000.\n\nRun the following docker ps command in your terminal to list your containers.\n\nsudo docker ps\n\n11.6.1 Next steps\nIn the previous section, you learned the basics about creating a Dockerfile to build a container image. Once you built an image, you started a container and saw the running app.\nNext, you‚Äôre going to make a modification to your app and learn how to update your running application with a new image. Along the way, you‚Äôll learn a few other useful commands."
  },
  {
    "objectID": "docker-start-update.html#update-the-source-code",
    "href": "docker-start-update.html#update-the-source-code",
    "title": "12¬† Update application",
    "section": "12.1 Update the source code",
    "text": "12.1 Update the source code\nIn the steps below, you will change the ‚Äúempty text‚Äù when you don‚Äôt have any todo list items to ‚ÄúYou have no todo items yet! Add one above!‚Äù\n\nIn the src/static/js/app.js file, update line 56 to use the new empty text (replace the text marked as - with the new text marked with +). Dont forget to save the changes.\n\n\n...\n -                &lt;p className=\"text-center\"&gt;No items yet! Add one above!&lt;/p&gt;\n +                &lt;p className=\"text-center\"&gt;You have no todo items yet! Add one above!&lt;/p&gt;\n ..."
  },
  {
    "objectID": "docker-start-update.html#build-image",
    "href": "docker-start-update.html#build-image",
    "title": "12¬† Update application",
    "section": "12.2 Build image",
    "text": "12.2 Build image\n\nBuild your updated version of the image, using the same docker build command you used in part 2.\n\nsudo docker build -t getting-started .\n\nStart a new container using the updated code.\n\nsudo docker run -dp 3000:3000 getting-started\nYou probably saw an error like this (the IDs will be different):\ndocker: Error response from daemon: driver failed programming external connectivity on endpoint competent_shirley (b83e81e06e1ad74187ac3d7248be33a557820d35d597877985804eecf3bfba69): Bind for 0.0.0.0:3000 failed: port is already allocated.\nThe error occurred because you aren‚Äôt able to start the new container while your old container is still running.\nThe reason is that the old container is already using the host‚Äôs port 3000 and only one process on the machine (containers included) can listen to a specific port. To fix this, you need to remove the old container."
  },
  {
    "objectID": "docker-start-update.html#remove-old-container",
    "href": "docker-start-update.html#remove-old-container",
    "title": "12¬† Update application",
    "section": "12.3 Remove old container",
    "text": "12.3 Remove old container\nTo remove a container, you first need to stop it. Once it has stopped, you can remove it.\n\nGet the ID of the container by using the docker ps command.\n\nsudo docker ps\n\nUse the docker stop command to stop the container. Replace  with the ID from docker ps.\n\nsudo docker stop &lt;the-container-id&gt;\n\nOnce the container has stopped, you can remove it by using the docker rm command.\n\nsudo docker rm &lt;the-container-id&gt;\nNote: You can also stop and remove a container in a single command by adding the force flag to the docker rm command. For example: docker rm -f &lt;the-container-id&gt;"
  },
  {
    "objectID": "docker-start-update.html#start-the-updated-app-container",
    "href": "docker-start-update.html#start-the-updated-app-container",
    "title": "12¬† Update application",
    "section": "12.4 Start the updated app container",
    "text": "12.4 Start the updated app container\nNow, start your updated app using the docker run command.\nsudo docker run -dp 3000:3000 getting-started\nRefresh your browser on http://localhost:3000 and you should see your updated help text."
  },
  {
    "objectID": "docker-start-update.html#next-steps",
    "href": "docker-start-update.html#next-steps",
    "title": "12¬† Update application",
    "section": "12.5 Next steps",
    "text": "12.5 Next steps\nWhile you were able to build an update, there were two things you might have noticed:\nAll of the existing items in your todo list are gone! That‚Äôs not a very good app! You‚Äôll fix that shortly.\nThere were a lot of steps involved for such a small change. In an upcoming section, you‚Äôll learn how to see code updates without needing to rebuild and start a new container every time you make a change. Before talking about persistence, you‚Äôll see how to share these images with others."
  },
  {
    "objectID": "docker-start-share.html#create-a-docker-id",
    "href": "docker-start-share.html#create-a-docker-id",
    "title": "13¬† Share the application",
    "section": "13.1 Create a Docker ID",
    "text": "13.1 Create a Docker ID\nDocker ID: A Docker ID allows you to access Docker Hub which is the world‚Äôs largest library and community for container images.\n\nCreate a Docker ID for free if you don‚Äôt have one."
  },
  {
    "objectID": "docker-start-share.html#create-a-repo",
    "href": "docker-start-share.html#create-a-repo",
    "title": "13¬† Share the application",
    "section": "13.2 Create a repo",
    "text": "13.2 Create a repo\nTo push an image, you first need to create a repository on Docker Hub.\n\nSign up or Sign in to Docker Hub.\nSelect the Create Repository button.\nFor the repo name, use getting-started. Make sure the Visibility is Public.\n\n\n\nSelect the Create button."
  },
  {
    "objectID": "docker-start-share.html#push-the-image",
    "href": "docker-start-share.html#push-the-image",
    "title": "13¬† Share the application",
    "section": "13.3 Push the image",
    "text": "13.3 Push the image\n\nIn the command line, try running the push command you see on Docker Hub. Note that your command will be using your namespace, not kirenz.\n\nsudo docker push kirenz/getting-started\nThis sould output an error message like the following:\nThe push refers to repository [docker.io/kirenz/getting-started]\nAn image does not exist locally with the tag: kirenz/getting-started\nTo fix this, you need to ‚Äútag‚Äù your existing image you‚Äôve built to give it another name.\n\nLogin to the Docker Hub using the command\n\nsudo docker login -u YOUR-USER-NAME\n\nUse the docker tag command to give the getting-started image a new name. Be sure to swap out YOUR-USER-NAME with your Docker ID.\n\nsudo docker tag getting-started YOUR-USER-NAME/getting-started\nTo learn more about the docker tag command, see docker tag.\n\nNow try your push command again. If you‚Äôre copying the value from Docker Hub, you can drop the tagname portion, as you didn‚Äôt add a tag to the image name. If you don‚Äôt specify a tag, Docker will use a tag called latest.\n\nsudo docker push YOUR-USER-NAME/getting-started\n\n13.3.1 Run image\nNow that your image has been built and pushed into a registry, try running your app on a brand new instance that has never seen this container image. To do this, you will use Play with Docker\n\nOpen your browser to Play with Docker.\nSelect Login and then select docker from the drop-down list.\n\n\n\nOnce you‚Äôre logged in, select the ADD NEW INSTANCE option on the left side bar. If you don‚Äôt see it, make your browser a little wider. After a few seconds, a terminal window opens in your browser.\nIn the terminal, start your freshly pushed app:\n\ndocker run -dp 3000:3000 YOUR-USER-NAME/getting-started\nYou should see the image get pulled down and eventually start up.\n\nSelect on the 3000 badge when it comes up and you should see the app with your modifications. If the 3000 badge doesn‚Äôt show up, you can select the Open Port button and type in 3000.\n\n!"
  },
  {
    "objectID": "docker-start-share.html#next-steps",
    "href": "docker-start-share.html#next-steps",
    "title": "13¬† Share the application",
    "section": "13.4 Next steps",
    "text": "13.4 Next steps\nIn this section, you learned how to share your images by pushing them to a registry. You then went to a brand new instance and were able to run the freshly pushed image. This is quite common in CI pipelines, where the pipeline will create the image and push it to a registry and then the production environment can use the latest version of the image.\nNow you can circle back around to what you noticed at the end of the last section. As a reminder, you noticed that when you restarted the app, you lost all of your todo list items. That‚Äôs obviously not a great user experience, so next you‚Äôll learn how you can persist the data across restarts."
  },
  {
    "objectID": "docker-start-persist.html#container-volumes",
    "href": "docker-start-persist.html#container-volumes",
    "title": "14¬† Persist the DB",
    "section": "14.1 Container volumes",
    "text": "14.1 Container volumes\nWhile containers can create, update, and delete files, those changes are lost when you remove the container and Docker isolates all changes to that container. With volumes, you can change all of this.\nVolumes provide the ability to connect specific filesystem paths of the container back to the host machine. If you mount a directory in the container, changes in that directory are also seen on the host machine. If you mount that same directory across container restarts, you‚Äôd see the same files.\nThere are two main types of volumes. You‚Äôll eventually use both, but you‚Äôll start with volume mounts."
  },
  {
    "objectID": "docker-start-persist.html#persist-the-todo-data",
    "href": "docker-start-persist.html#persist-the-todo-data",
    "title": "14¬† Persist the DB",
    "section": "14.2 Persist the todo data",
    "text": "14.2 Persist the todo data\nBy default, the todo app stores its data in a SQLite database at /etc/todos/todo.db in the container‚Äôs filesystem. If you‚Äôre not familiar with SQLite, no worries! It‚Äôs simply a relational database that stores all the data in a single file. While this isn‚Äôt the best for large-scale applications, it works for small demos. You‚Äôll learn how to switch this to a different database engine later.\nWith the database being a single file, if you can persist that file on the host and make it available to the next container, it should be able to pick up where the last one left off. By creating a volume and attaching (often called ‚Äúmounting‚Äù) it to the directory where you stored the data, you can persist the data. As your container writes to the todo.db file, it will persist the data to the host in the volume.\nAs mentioned, you‚Äôre going to use a volume mount. Think of a volume mount as an opaque bucket of data. Docker fully manages the volume, including the storage location on disk. You only need to remember the name of the volume.\n\nCreate a volume by using the docker volume create command. We call the volume todo-db:\n\nsudo docker volume create todo-db\n\nStop and remove the todo app container once again, as it is still running without using the persistent volume (obtain the container id with sudo docker ps):\n\nsudo docker rm -f &lt;id&gt;\n\nStart the todo app container, but add the --mount option to specify a volume mount. Give the volume a name, and mount it to /etc/todos in the container, which captures all files created at the path:\n\nsudo docker run -dp 3000:3000 --mount type=volume,src=todo-db,target=/etc/todos getting-started\n\nOnce the container starts up, go to PORTS, open the app and add a few items to your todo list.\nStop and remove the container for the todo app. Use sudo docker ps to get the ID and then docker rm -f &lt;id&gt; to remove it.\nStart a new container:\n\nsudo docker run -dp 3000:3000 --mount type=volume,src=todo-db,target=/etc/todos getting-started\n\nOpen the app. You should see your items still in your list.\nGo ahead and remove the container when you‚Äôre done checking out your list.\n\nIf you want to know the location of your stored data, you can use the docker volume inspect command:\nsudo docker volume inspect todo-db\nThe Mountpoint is the actual location of the data on the disk."
  },
  {
    "objectID": "docker-start-persist.html#next-steps",
    "href": "docker-start-persist.html#next-steps",
    "title": "14¬† Persist the DB",
    "section": "14.3 Next steps",
    "text": "14.3 Next steps\nAt this point, you have a functioning application that can survive restarts.\nHowever, you saw earlier that rebuilding images for every change takes quite a bit of time. There‚Äôs got to be a better way to make changes, right? With bind mounts, there is a better way."
  },
  {
    "objectID": "docker-start-bind-mounts.html#quick-volume-type-comparisons",
    "href": "docker-start-bind-mounts.html#quick-volume-type-comparisons",
    "title": "15¬† Use bind mounts",
    "section": "15.1 Quick volume type comparisons",
    "text": "15.1 Quick volume type comparisons\nThe following table outlines the main differences between volume mounts and bind mounts.\n\n\n\n\n\n\n\n\n\nNamed volumes\nBind mounts\n\n\n\n\nHost location\nDocker chooses\nYou decide\n\n\nMount example (using¬†--mount)\ntype=volume,src=my-volume,target=/usr/local/data\ntype=bind,src=/path/to/data,target=/usr/local/data\n\n\nPopulates new volume with container contents\nYes\nNo\n\n\nSupports Volume Drivers\nYes\nNo"
  },
  {
    "objectID": "docker-start-bind-mounts.html#trying-out-bind-mounts",
    "href": "docker-start-bind-mounts.html#trying-out-bind-mounts",
    "title": "15¬† Use bind mounts",
    "section": "15.2 Trying out bind mounts",
    "text": "15.2 Trying out bind mounts\nBefore looking at how we can use bind mounts for developing our application, let‚Äôs run a quick experiment to get a practical understanding of how bind mounts work.\nUse your integrated VS Code terminal and make sure your current working directory is in the app directory of the getting started repository.\n\nRun the following command to start bash in an ubuntu container with a bind mount.\n\nsudo docker run -it --mount type=bind,src=\"$(pwd)\",target=/src ubuntu bash\nThe --mount option tells Docker to create a bind mount, where src is the current working directory on your host machine (getting-started/app), and target is where that directory should appear inside the container (/src).\nAfter running the command, Docker starts an interactive bash session in the root directory of the container‚Äôs filesystem.\n\nNow, change directory in the src directory:\n\ncd src\n\nThis is the directory that you mounted when starting the container. Listing the contents of this directory using ls displays the same files as in the getting-started/app directory on your host machine:\n\nls\n\nCreate a new file named myfile.txt using touch:\n\ntouch myfile.txt\n\nTake a look at the VS Code File Explorer. You‚Äôll see the myfile.txt file has been created in the directory.\nIn the VS Code Explorer, delete the myfile.txt file.\nIn the container, list the contents of the app directory once more. You‚Äôll see that the file is now gone.\n\nls\n\nStop the interactive container session with Ctrl + D.\n\nAnd that‚Äôs all for a brief introduction to bind mounts. This procedure demonstrated how files are shared between the host and the container, and how changes are immediately reflected on both sides. Now let‚Äôs see how we can use bind mounts to develop software."
  },
  {
    "objectID": "docker-start-bind-mounts.html#run-your-app-in-a-development-container",
    "href": "docker-start-bind-mounts.html#run-your-app-in-a-development-container",
    "title": "15¬† Use bind mounts",
    "section": "15.3 Run your app in a development container",
    "text": "15.3 Run your app in a development container\nThe following steps describe how to run a development container with a bind mount that does the following:\n\nMount our source code into the container\nInstall all dependencies\nStart nodemon to watch for filesystem changes\n\nFirst, make sure you don‚Äôt have any getting-started containers currently running. If necessary, remove the container using rm -f &lt;the-container-id&gt;\n\nRun the following command (from the getting-started/app directory).\n\ndocker run -dp 3000:3000 \\\n    -w /app --mount type=bind,src=\"$(pwd)\",target=/app \\\n    node:18-alpine \\\n    sh -c \"yarn install && yarn run dev\"\n-dp 3000:3000 - same as before. Run in detached (background) mode and create a port mapping\n-w /app - sets the ‚Äúworking directory‚Äù or the current directory that the command will run from\n-mount type=bind,src=\"$(pwd)\",target=/app - bind mount the current directory from the host into the /app directory in the container\nnode:18-alpine - the image to use. Note that this is the base image for our app from the Dockerfile\nsh -c \"yarn install && yarn run dev\". We‚Äôre starting a shell using sh (alpine doesn‚Äôt have bash) and running yarn install to install packages and then running yarn run dev to start the development server. If we look in the package.json, we‚Äôll see that the dev script starts nodemon.\n\nGet your Docker container-id:\n\nsudo docker ps\n\nYou can watch the logs using docker logs &lt;container-id&gt;:\n\nsudo docker logs &lt;container-id&gt;\nYou‚Äôll know you‚Äôre ready to go when you see this:\nyarn install v1.22.19\n[1/4] Resolving packages...\n[2/4] Fetching packages...\n[3/4] Linking dependencies...\n[4/4] Building fresh packages...\nDone in 15.17s.\nyarn run v1.22.19\n$ nodemon src/index.js\n[nodemon] 2.0.20\n[nodemon] to restart at any time, enter `rs`\n[nodemon] watching path(s): *.*\n[nodemon] watching extensions: js,mjs,json\n[nodemon] starting `node src/index.js`\nUsing sqlite database at /etc/todos/todo.db\nListening on port 3000\nWhen you‚Äôre done watching the logs, exit out by hitting Ctrl+C.\n\nNow, make a change to the app. In the src/static/js/app.js file, on line 109, change the ‚ÄúAdd Item‚Äù button to simply say ‚ÄúAdd‚Äù:\n\n- {submitting ? 'Adding...' : 'Add Item'}\n+ {submitting ? 'Adding...' : 'Add'}\n\nSave the file.\nRefresh the page in your web browser, and you should see the change reflected almost immediately. It might take a few seconds for the Node server to restart. If you get an error, try refreshing after a few seconds.\n\nFeel free to make any other changes you‚Äôd like to make. Each time you make a change and save a file, the nodemon process restarts the app inside the container automatically.\n\nWhen you‚Äôre done, stop the container and build your new image using:\n\nsudo docker build -t getting-started .\nUsing bind mounts is common for local development setups. The advantage is that the development machine doesn‚Äôt need to have all of the build tools and environments installed. With a single docker run command, dependencies and tools are pulled and ready to go.\nWe‚Äôll talk about Docker Compose in a future step, as this will help simplify our commands (we‚Äôre already getting a lot of flags).\nIn addition to volume mounts and bind mounts, Docker also supports other mount types and storage drivers for handling more complex and specialized use cases. To learn more about the advanced storage concepts, see Manage data in Docker."
  },
  {
    "objectID": "docker-start-bind-mounts.html#next-steps",
    "href": "docker-start-bind-mounts.html#next-steps",
    "title": "15¬† Use bind mounts",
    "section": "15.4 Next steps",
    "text": "15.4 Next steps\nAt this point, you can persist your database and respond rapidly to the needs and demands of your investors and founders. Hooray! But, guess what? You received great news! Your project has been selected for future development!\nIn order to prepare for production, you need to migrate your database from working in SQLite to something that can scale a little better. For simplicity, you‚Äôll keep with a relational database and switch your application to use MySQL. But, how should you run MySQL? How do you allow the containers to talk to each other? You‚Äôll learn about that next!"
  },
  {
    "objectID": "docker-start-multi-container.html#container-networking",
    "href": "docker-start-multi-container.html#container-networking",
    "title": "16¬† Multi container apps",
    "section": "16.1 Container networking",
    "text": "16.1 Container networking\nRemember that containers, by default, run in isolation and don‚Äôt know anything about other processes or containers on the same machine. So, how do you allow one container to talk to another? The answer is networking. If you place the two containers on the same network, they can talk to each other."
  },
  {
    "objectID": "docker-start-multi-container.html#start-mysql",
    "href": "docker-start-multi-container.html#start-mysql",
    "title": "16¬† Multi container apps",
    "section": "16.2 Start MySQL",
    "text": "16.2 Start MySQL\nThere are two ways to put a container on a network:\n\nAssign the network when starting the container.\nConnect an already running container to a network.\n\nIn the following steps, you‚Äôll create the network first and then attach the MySQL container at startup.\n\nCreate the network:\n\nsudo docker network create todo-app\n\nStart a MySQL container and attach it to the network. You‚Äôre also going to define a few environment variables that the database will use to initialize the database. To learn more about the MySQL environment variables, see the ‚ÄúEnvironment Variables‚Äù section in the MySQL Docker Hub listing.\n\nsudo docker run -d \\\n     --network todo-app --network-alias mysql \\\n     -v todo-mysql-data:/var/lib/mysql \\\n     -e MYSQL_ROOT_PASSWORD=secret \\\n     -e MYSQL_DATABASE=todos \\\n     mysql:8.0\nIn the command above, you‚Äôll see the --network-alias flag. In a later section, you‚Äôll learn more about this flag.\nYou‚Äôll notice a volume named todo-mysql-data in the above command that is mounted at /var/lib/mysql, which is where MySQL stores its data. However, you never ran a docker volume create command. Docker recognizes you want to use a named volume and creates one automatically for you.\n\nTo confirm you have the database up and running, connect to the database and verify that it connects.\n\nsudo docker exec -it &lt;mysql-container-id&gt; mysql -u root -p\nWhen the password prompt comes up, type in secret.\n\nIn the MySQL shell, list the databases and verify you see the todos database:\n\nSHOW DATABASES;\nYou should see output that looks like this:\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| mysql              |\n| performance_schema |\n| sys                |\n| todos              |\n+--------------------+\n5 rows in set (0.01 sec)\n\nExit the MySQL shell to return to the shell.\n\nexit\nYou now have a todos database and it‚Äôs ready for you to use."
  },
  {
    "objectID": "docker-start-multi-container.html#connect-to-mysql",
    "href": "docker-start-multi-container.html#connect-to-mysql",
    "title": "16¬† Multi container apps",
    "section": "16.3 Connect to MySQL",
    "text": "16.3 Connect to MySQL\nNow that you know MySQL is up and running, you can use it. But, how do you use it? If you run another container on the same network, how do you find the container? Remember that each container has its own IP address.\nTo answer the questions above and better understand container networking, you‚Äôre going to make use of the nicolaka/netshoot container, which ships with a lot of tools that are useful for troubleshooting or debugging networking issues.\n\nStart a new container using the nicolaka/netshoot image. Make sure to connect it to the same network.\n\nsudo docker run -it --network todo-app nicolaka/netshoot\n\nInside the container, you‚Äôre going to use the dig command, which is a useful DNS tool. You‚Äôre going to look up the IP address for the hostname mysql.\n\ndig mysql\nYou should get output like the following.\n; &lt;&lt;&gt;&gt; DiG 9.18.13 &lt;&lt;&gt;&gt; mysql\n;; global options: +cmd\n;; Got answer:\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 35945\n;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0\n\n;; QUESTION SECTION:\n;mysql.                         IN      A\n\n;; ANSWER SECTION:\nmysql.                  600     IN      A       172.18.0.2\n\n;; Query time: 0 msec\n;; SERVER: 127.0.0.11#53(127.0.0.11) (UDP)\n;; WHEN: Sat May 13 11:00:51 UTC 2023\n;; MSG SIZE  rcvd: 44\nIn the ‚ÄúANSWER SECTION‚Äù, you will see an A record for mysql that resolves to 172.18.0.2 (your IP address will most likely have a different value). While mysql isn‚Äôt normally a valid hostname, Docker was able to resolve it to the IP address of the container that had that network alias. Remember, you used the --network-alias earlier.\nWhat this means is that your app only simply needs to connect to a host named mysql and it‚Äôll talk to the database.\n\nType exit to leave the Netshoot shell:\n\nexit"
  },
  {
    "objectID": "docker-start-multi-container.html#run-your-app-with-mysql",
    "href": "docker-start-multi-container.html#run-your-app-with-mysql",
    "title": "16¬† Multi container apps",
    "section": "16.4 Run your app with MySQL",
    "text": "16.4 Run your app with MySQL\nThe todo app supports the setting of a few environment variables to specify MySQL connection settings. They are:\n\nMYSQL_HOST - the hostname for the running MySQL server\nMYSQL_USER - the username to use for the connection\nMYSQL_PASSWORD - the password to use for the connection\nMYSQL_DB - the database to use once connected\n\n\n\n\n\n\n\nWhile using env vars to set connection settings is generally accepted for development, it‚Äôs highly discouraged when running applications in production. Diogo Monica, a former lead of security at Docker, wrote a fantastic blog post explaining why.\nA more secure mechanism is to use the secret support provided by your container orchestration framework. In most cases, these secrets are mounted as files in the running container. You‚Äôll see many apps (including the MySQL image and the todo app) also support env vars with a _FILE suffix to point to a file containing the variable.\nAs an example, setting the MYSQL_PASSWORD_FILE var will cause the app to use the contents of the referenced file as the connection password. Docker doesn‚Äôt do anything to support these env vars. Your app will need to know to look for the variable and get the file contents.\n\n\n\nYou can now start your dev-ready container.\n\nFirst, remove any old getting-started containers (keep the mysql container)\n\nsudo docker remove -f &lt;container-id&gt;\n\nSpecify each of the environment variables above, as well as connect the container to your app network. As before, make sure that you are in the getting-started/app directory when you run this command:\n\nsudo docker run -dp 3000:3000 \\\n   -w /app -v \"$(pwd):/app\" \\\n   --network todo-app \\\n   -e MYSQL_HOST=mysql \\\n   -e MYSQL_USER=root \\\n   -e MYSQL_PASSWORD=secret \\\n   -e MYSQL_DB=todos \\\n   node:18-alpine \\\n   sh -c \"yarn install && yarn run dev\"\n\nIf you look at the logs for the container (docker logs -f &lt;container-id&gt;), you should see a message similar to the following, which indicates it‚Äôs using the mysql database.\n\nyarn install v1.22.19\n[1/4] Resolving packages...\nsuccess Already up-to-date.\nDone in 0.43s.\nyarn run v1.22.19\n$ nodemon src/index.js\n[nodemon] 2.0.20\n[nodemon] to restart at any time, enter `rs`\n[nodemon] watching path(s): *.*\n[nodemon] watching extensions: js,mjs,json\n[nodemon] starting `node src/index.js`\nWaiting for mysql:3306.\nConnected!\nConnected to mysql db at host mysql\nListening on port 3000\n\nWhen you‚Äôre done watching the logs, exit out by hitting Ctrl+C.\nOpen the app in your browser and add a few items to your todo list.\nConnect to the mysql database and prove that the items are being written to the database. Remember, the password is secret.\n\nsudo  docker exec -it &lt;mysql-container-id&gt; mysql -p todos\n\nAnd in the mysql shell, run the following:\n\nSELECT * FROM todo_items;\nThis should output a table with your stored items.\n\nTo leave the MySQL-shell, simply type exit"
  },
  {
    "objectID": "docker-start-multi-container.html#next-steps",
    "href": "docker-start-multi-container.html#next-steps",
    "title": "16¬† Multi container apps",
    "section": "16.5 Next steps",
    "text": "16.5 Next steps\nAt this point, you have an application that now stores its data in an external database running in a separate container. You learned a little bit about container networking and service discovery using DNS.\nBut, there‚Äôs a good chance you are starting to feel a little overwhelmed with everything you need to do to start up this application. You have to create a network, start containers, specify all of the environment variables, expose ports, and more! That‚Äôs a lot to remember and it‚Äôs certainly making things harder to pass along to someone else.\nIn the next section, you‚Äôll learn about Docker Compose. With Docker Compose, you can share your application stacks in a much easier way and let others spin them up with a single, simple command."
  },
  {
    "objectID": "docker-start-compose.html#check-docker-compose-installation",
    "href": "docker-start-compose.html#check-docker-compose-installation",
    "title": "17¬† Use Docker Compose",
    "section": "17.1 Check Docker compose installation",
    "text": "17.1 Check Docker compose installation\n\nVerify that Docker Compose is installed correctly by checking the version.\n\ndocker compose version\nThis should output something like Docker Compose version v2.17.3\nIf you don‚Äôt get any output, install Docker compose.\n\nUpdate the package index:\n\nsudo apt-get update\n\nInstall the latest version of Docker Compose:\n\nsudo apt-get install docker-compose-plugin"
  },
  {
    "objectID": "docker-start-compose.html#create-the-compose-file",
    "href": "docker-start-compose.html#create-the-compose-file",
    "title": "17¬† Use Docker Compose",
    "section": "17.2 Create the Compose file",
    "text": "17.2 Create the Compose file\n\nAt the root of the /getting-started/app folder, create a file named docker-compose.yml:\n\ntouch docker-compose.yml\n\nOpen the file in the VS Code Explorer."
  },
  {
    "objectID": "docker-start-compose.html#define-the-app-service",
    "href": "docker-start-compose.html#define-the-app-service",
    "title": "17¬† Use Docker Compose",
    "section": "17.3 Define the app service",
    "text": "17.3 Define the app service\nTo remember, this was the command we were using to define our app container.\ndocker run -dp 3000:3000 \\\n  -w /app -v \"$(pwd):/app\" \\\n  --network todo-app \\\n  -e MYSQL_HOST=mysql \\\n  -e MYSQL_USER=root \\\n  -e MYSQL_PASSWORD=secret \\\n  -e MYSQL_DB=todos \\\n  node:18-alpine \\\n  sh -c \"yarn install && yarn run dev\"\n\nIn the compose file, we‚Äôll start off by defining the list of services (or containers) we want to run as part of our application.\n\nservices:\n\nLet‚Äôs define the service entry and the image for the container. We can pick any name for the service. The name will automatically become a network alias, which will be useful when defining our MySQL service.\n\nservices:\n  app:\n    image: node:18-alpine\n\nTypically, you will see the command close to the image definition, although there is no requirement on ordering. So, let‚Äôs go ahead and move that into our file.\n\nservices:\n  app:\n    image: node:18-alpine\n    command: sh -c \"yarn install && yarn run dev\"\n\nLet‚Äôs migrate the -p 3000:3000 part of the command by defining the ports for the service. We will use the short syntax here, but there is also a more verbose long syntax available as well.\n\nservices:\n  app:\n    image: node:18-alpine\n    command: sh -c \"yarn install && yarn run dev\"\n    ports:\n      - 3000:3000\n\nNext, we‚Äôll migrate both the working directory (-w /app) and the volume mapping (-v \"$(pwd):/app\") by using the working_dir and volumes definitions. Volumes also has a short and long syntax. One advantage of Docker Compose volume definitions is we can use relative paths from the current directory.\n\nservices:\n  app:\n    image: node:18-alpine\n    command: sh -c \"yarn install && yarn run dev\"\n    ports:\n      - 3000:3000\n    working_dir: /app\n    volumes:\n      - ./:/app\n\nFinally, we need to migrate the environment variable definitions using the environment key.\n\nservices:\n  app:\n    image: node:18-alpine\n    command: sh -c \"yarn install && yarn run dev\"\n    ports:\n      - 3000:3000\n    working_dir: /app\n    volumes:\n      - ./:/app\n    environment:\n      MYSQL_HOST: mysql\n      MYSQL_USER: root\n      MYSQL_PASSWORD: secret\n      MYSQL_DB: todos\n\nCopy and paste all of the contents in your file and save the changes."
  },
  {
    "objectID": "docker-start-compose.html#define-the-mysql-service",
    "href": "docker-start-compose.html#define-the-mysql-service",
    "title": "17¬† Use Docker Compose",
    "section": "17.4 Define the MySQL service",
    "text": "17.4 Define the MySQL service\nNow, it‚Äôs time to define the MySQL service. The command that we used for that container was the following:\ndocker run -d \\\n  --network todo-app --network-alias mysql \\\n  -v todo-mysql-data:/var/lib/mysql \\\n  -e MYSQL_ROOT_PASSWORD=secret \\\n  -e MYSQL_DATABASE=todos \\\n  mysql:8.0\nWe will first define the new service and name it mysql so it automatically gets the network alias. We‚Äôll go ahead and specify the image to use as well.\nservices:\n  app:\n    # The app service definition\n  mysql:\n    image: mysql:8.0\nNext, we‚Äôll define the volume mapping. When we ran the container with docker run, the named volume was created automatically. However, that doesn‚Äôt happen when running with Compose. We need to define the volume in the top-level volumes: section and then specify the mountpoint in the service config. By simply providing only the volume name, the default options are used. There are many more options available though.\nservices:\n  app:\n    # The app service definition\n  mysql:\n    image: mysql:8.0\n    volumes:\n      - todo-mysql-data:/var/lib/mysql\n\nvolumes:\n  todo-mysql-data:\n\nFinally, we only need to specify the environment variables.\n\nservices:\n  app:\n    # The app service definition\n  mysql:\n    image: mysql:8.0\n    volumes:\n      - todo-mysql-data:/var/lib/mysql\n    environment:\n      MYSQL_ROOT_PASSWORD: secret\n      MYSQL_DATABASE: todos\n\nvolumes:\n  todo-mysql-data:\nAt this point, our complete docker-compose.yml should look like this:\nservices:\n  app:\n    image: node:18-alpine\n    command: sh -c \"yarn install && yarn run dev\"\n    ports:\n      - 3000:3000\n    working_dir: /app\n    volumes:\n      - ./:/app\n    environment:\n      MYSQL_HOST: mysql\n      MYSQL_USER: root\n      MYSQL_PASSWORD: secret\n      MYSQL_DB: todos\n\n  mysql:\n    image: mysql:8.0\n    volumes:\n      - todo-mysql-data:/var/lib/mysql\n    environment:\n      MYSQL_ROOT_PASSWORD: secret\n      MYSQL_DATABASE: todos\n\nvolumes:\n  todo-mysql-data:"
  },
  {
    "objectID": "docker-start-compose.html#run-the-application-stack",
    "href": "docker-start-compose.html#run-the-application-stack",
    "title": "17¬† Use Docker Compose",
    "section": "17.5 Run the application stack",
    "text": "17.5 Run the application stack\nNow that we have our docker-compose.yml file, we can start it up!\n\nMake sure no other copies of the app/db are running first (sudo docker ps and sudo docker rm -f &lt;ids&gt;). Remove all of them.\nStart up the application stack using the docker compose up command. We‚Äôll add the -d flag to run everything in the background.\n\nsudo docker compose up -d\nWhen we run this, we should see output like this:\n\n[+] Running 4/4\n ‚úî Network app_default           Creat...                       0.1s \n ‚úî Volume \"app_todo-mysql-data\"  Created                        0.0s \n ‚úî Container app-mysql-1         Sta...                         0.8s \n ‚úî Container app-app-1           Start...                       0.8s \nYou‚Äôll notice that the volume was created as well as a network! By default, Docker Compose automatically creates a network specifically for the application stack (which is why we didn‚Äôt define one in the compose file).\n\nLet‚Äôs look at the logs using the sudo docker compose logs -f command.\n\nYou‚Äôll see the logs from each of the services interleaved into a single stream. This is useful when you want to watch for timing-related issues. The -f flag ‚Äúfollows‚Äù the log, so will give you live output as it‚Äôs generated.\nThe service name is displayed at the beginning of the line (often colored) to help distinguish messages. If you want to view the logs for a specific service, you can add the service name to the end of the logs command (for example, sudo docker compose logs -f app).\n\nAt this point, you should be able to open your app and see it running."
  },
  {
    "objectID": "docker-start-compose.html#tear-it-all-down",
    "href": "docker-start-compose.html#tear-it-all-down",
    "title": "17¬† Use Docker Compose",
    "section": "17.6 Tear it all down",
    "text": "17.6 Tear it all down\nWhen you‚Äôre ready to tear it all down, simply run docker compose down for the entire app. The containers will stop and the network will be removed.\n::: {.callout-caution}"
  },
  {
    "objectID": "docker-start-compose.html#removing-volumes",
    "href": "docker-start-compose.html#removing-volumes",
    "title": "17¬† Use Docker Compose",
    "section": "17.7 Removing Volumes",
    "text": "17.7 Removing Volumes\nBy default, named volumes in your compose file are NOT removed when running docker compose down. If you want to remove the volumes, you will need to add the --volumes flag."
  },
  {
    "objectID": "docker-start-compose.html#next-steps",
    "href": "docker-start-compose.html#next-steps",
    "title": "17¬† Use Docker Compose",
    "section": "17.8 Next steps",
    "text": "17.8 Next steps\nIn this section, you learned about Docker Compose and how it helps you dramatically simplify the defining and sharing of multi-service applications. You created a Compose file by translating the commands you were using into the appropriate compose format.\nAt this point, you‚Äôre starting to wrap up the tutorial. However, there are a few best practices about image building you should cover, as there is a big issue with the Dockerfile you‚Äôve been using."
  },
  {
    "objectID": "docker-start-best-practices.html#image-layering",
    "href": "docker-start-best-practices.html#image-layering",
    "title": "18¬† Image-building best practices",
    "section": "18.1 Image layering",
    "text": "18.1 Image layering\nDid you know that you can look at what makes up an image? Using the docker image history command, you can see the command that was used to create each layer within an image.\n\nUse the docker image history command to see the layers in the getting-started image you created earlier in the tutorial.\n\nsudo docker image history getting-started\nEach of the lines in the output represents a layer in the image. Using this, you can also quickly see the size of each layer, helping diagnose large images.\n\nYou‚Äôll notice that several of the lines are truncated. If you add the --no-trunc flag, you‚Äôll get the full output:\n\nsudo docker image history --no-trunc getting-started"
  },
  {
    "objectID": "docker-start-best-practices.html#layer-caching",
    "href": "docker-start-best-practices.html#layer-caching",
    "title": "18¬† Image-building best practices",
    "section": "18.2 Layer caching",
    "text": "18.2 Layer caching\nNow that you‚Äôve seen the layering in action, there‚Äôs an important lesson to learn to help decrease build times for your container images.\n\nOnce a layer changes, all downstream layers have to be recreated as well\n\nLet‚Äôs look at the Dockerfile we were using one more time‚Ä¶\n# syntax=docker/dockerfile:1\nFROM node:18-alpine\nWORKDIR /app\nCOPY . .\nRUN yarn install --production\nCMD [\"node\", \"src/index.js\"]\nGoing back to the image history output, we see that each command in the Dockerfile becomes a new layer in the image. You might remember that when we made a change to the image, the yarn dependencies had to be reinstalled. Is there a way to fix this? It doesn‚Äôt make much sense to ship around the same dependencies every time we build, right?\nTo fix this, we need to restructure our Dockerfile to help support the caching of the dependencies. For Node-based applications, those dependencies are defined in the package.json file. So, what if we copied only that file in first, install the dependencies, and then copy in everything else? Then, we only recreate the yarn dependencies if there was a change to the package.json. Make sense?\n\nUpdate the Dockerfile to copy in the package.json first, install dependencies, and then copy everything else in.\n\n# syntax=docker/dockerfile:1\nFROM node:18-alpine\nWORKDIR /app\nCOPY package.json yarn.lock ./\nRUN yarn install --production\nCOPY . .\nCMD [\"node\", \"src/index.js\"]\nEXPOSE 3000\n\nNext, we create a file named .dockerignore (in the same folder as the Dockerfile) and include the text node_modules. We use the terminal to accomplish this:\n\necho \"node_modules\" &gt; .dockerignore\n.dockerignore files are an easy way to selectively copy only image relevant files. You can read more about this here.\nIn this case, the node_modules folder should be omitted in the second COPY step because otherwise, it would possibly overwrite files which were created by the command in the RUN step. For further details on why this is recommended for Node.js applications and other best practices, have a look at their guide on Dockerizing a Node.js web app\n\nBuild a new image using docker build.\n\nsudo docker build -t getting-started .\nYou should see output like this‚Ä¶\n[+] Building 15.4s (10/10) FINISHED                                \n =&gt; [internal] load build definition from Dockerfile          0.2s\n =&gt; =&gt; transferring dockerfile: 182B                          0.0s\n =&gt; [internal] load .dockerignore                             0.3s\n =&gt; =&gt; transferring context: 53B                              0.0s\n =&gt; [internal] load metadata for docker.io/library/node:18-a  0.0s\n =&gt; [internal] load build context                             0.2s\n =&gt; =&gt; transferring context: 3.22kB                           0.2s\n =&gt; [1/5] FROM docker.io/library/node:18-alpine               0.0s\n =&gt; CACHED [2/5] WORKDIR /app                                 0.0s\n =&gt; [3/5] COPY package.json yarn.lock ./                      0.7s\n =&gt; [4/5] RUN yarn install --production                      12.2s\n =&gt; [5/5] COPY . .                                            0.5s\n =&gt; exporting to image                                        1.5s\n =&gt; =&gt; exporting layers                                       1.5s\n =&gt; =&gt; writing image sha256:19dfa47bc86d7dceaa01a048c43a7dbc  0.0s\n =&gt; =&gt; naming to docker.io/library/getting-started            0.0s\nYou‚Äôll see that all layers were rebuilt. Perfectly fine since we changed the Dockerfile quite a bit.\n\nNow, make a change to the src/static/index.html file (like change the &lt;title&gt; to say ‚ÄúThe Awesome Todo App‚Äù in line 11).\nBuild the Docker image now using sudo docker build -t getting-started . again. This time, your output should look a little different.\n\n =&gt; [internal] load build definition from Dockerfile          0.2s\n =&gt; =&gt; transferring dockerfile: 182B                          0.0s\n =&gt; [internal] load .dockerignore                             0.3s\n =&gt; =&gt; transferring context: 53B                              0.0s\n =&gt; [internal] load metadata for docker.io/library/node:18-a  0.0s\n =&gt; [1/5] FROM docker.io/library/node:18-alpine               0.0s\n =&gt; [internal] load build context                             0.0s\n =&gt; =&gt; transferring context: 3.45kB                           0.0s\n =&gt; CACHED [2/5] WORKDIR /app                                 0.0s\n =&gt; CACHED [3/5] COPY package.json yarn.lock ./               0.0s\n =&gt; CACHED [4/5] RUN yarn install --production                0.0s\n =&gt; [5/5] COPY . .                                            0.3s\n =&gt; exporting to image                                        0.1s\n =&gt; =&gt; exporting layers                                       0.1s\n =&gt; =&gt; writing image sha256:a85579d9ee5192bc7593ad0b2f263d25  0.0s\n =&gt; =&gt; naming to docker.io/library/getting-started            0.0s\nFirst off, you should notice that the build was MUCH faster! And, you‚Äôll see that several steps are using previously cached layers. So, yes! We‚Äôre using the build cache. Pushing and pulling this image and updates to it will be much faster as well."
  },
  {
    "objectID": "docker-start-best-practices.html#next-steps",
    "href": "docker-start-best-practices.html#next-steps",
    "title": "18¬† Image-building best practices",
    "section": "18.3 Next steps",
    "text": "18.3 Next steps\nBy understanding a little bit about the structure of images, you can build images faster and ship fewer changes. Scanning images gives you confidence that the containers you are running and distributing are secure.\n\nIn the next section, you‚Äôll learn about additional resources you can use to continue learning about containers."
  },
  {
    "objectID": "docker-start-next.html#container-orchestration-with-kubernetes",
    "href": "docker-start-next.html#container-orchestration-with-kubernetes",
    "title": "19¬† What next?",
    "section": "19.1 Container orchestration with Kubernetes",
    "text": "19.1 Container orchestration with Kubernetes\nRunning containers in production is tough. You don‚Äôt want to log into a machine and simply run a docker run or docker-compose up. Why not? Well, what happens if the containers die? How do you scale across several machines? Container orchestration solves this problem. Tools like Kubernetes help solve this problem.\nThe general idea is that you have ‚Äúmanagers‚Äù who receive expected state. This state might be ‚ÄúI want to run two instances of my web app and expose port 80.‚Äù The managers then look at all of the machines in the cluster and delegate work to ‚Äúworker‚Äù nodes. The managers watch for changes (such as a container quitting) and then work to make actual state reflect the expected state.\nWe will cover Kubernetes in the next chapter."
  },
  {
    "objectID": "k8s.html#what-is-kubernetes",
    "href": "k8s.html#what-is-kubernetes",
    "title": "Kubernetes",
    "section": "What is Kubernetes?",
    "text": "What is Kubernetes?\nKubernetes, also known as K8s, is an open-source system for automating deployment, scaling, and management of containerized applications. It provides you with the framework to run distributed systems resiliently, scale them as needed, roll out new software seamlessly, and more."
  },
  {
    "objectID": "k8s.html#why-kubernetes",
    "href": "k8s.html#why-kubernetes",
    "title": "Kubernetes",
    "section": "Why Kubernetes?",
    "text": "Why Kubernetes?\n\nPortability: Kubernetes runs on various platforms, from your laptop to public cloud providers.\nScalability: It can scale your applications based on the demand, thereby optimizing resource usage.\nHigh availability: Kubernetes ensures that your applications are always available to the end-users."
  },
  {
    "objectID": "k8s.html#core-concepts-of-kubernetes",
    "href": "k8s.html#core-concepts-of-kubernetes",
    "title": "Kubernetes",
    "section": "Core Concepts of Kubernetes",
    "text": "Core Concepts of Kubernetes\n\nPods: The smallest and simplest unit in the Kubernetes object model that you create or deploy.\nServices: An abstract way to expose an application running on a set of Pods as a network service.\nVolumes: Provides persistent storage for your application data.\nNamespaces: Kubernetes supports multiple virtual clusters backed by the same physical cluster."
  },
  {
    "objectID": "k8s.html#kubernetes-architecture",
    "href": "k8s.html#kubernetes-architecture",
    "title": "Kubernetes",
    "section": "Kubernetes Architecture",
    "text": "Kubernetes Architecture\nKubernetes follows a client-server architecture. It‚Äôs divided into two main components: - Master Node: This controls the Kubernetes nodes. It‚Äôs the entry point for all administrative tasks. - Worker Nodes: These are the machines where the applications are running."
  },
  {
    "objectID": "k8s-setup.html#prerequisites",
    "href": "k8s-setup.html#prerequisites",
    "title": "20¬† Kubernetes setup",
    "section": "20.1 Prerequisites",
    "text": "20.1 Prerequisites\nTo create clusters with kind, you will first need to install Docker. If you haven‚Äôt already, install Docker, following these instructions."
  },
  {
    "objectID": "k8s-setup.html#kind-installation",
    "href": "k8s-setup.html#kind-installation",
    "title": "20¬† Kubernetes setup",
    "section": "20.2 Kind installation",
    "text": "20.2 Kind installation\nkind (Kubernetes IN Docker) is a tool for running local Kubernetes clusters using Docker container ‚Äúnodes‚Äù.\n\nWe follow the official installation guide and download the latest binary (v0.18.0 at the time of this writing).\n\nsudo curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.18.0/kind-linux-amd64\n\nChange permissions and rename it to kind:\n\nsudo chmod +x ./kind\n\nMove the folder to /usr/local/bin/kind\n\nsudo mv ./kind /usr/local/bin/kind\n\n20.2.1 Creating a Cluster\n\nCreating a Kubernetes cluster is as simple as kind create cluster (visit this site to learn more).\n\nsudo kind create cluster\nThis will bootstrap a Kubernetes cluster using a pre-built node image. Prebuilt images are hosted at kindest/node."
  },
  {
    "objectID": "k8s-setup.html#kubectl-installation",
    "href": "k8s-setup.html#kubectl-installation",
    "title": "20¬† Kubernetes setup",
    "section": "20.3 kubectl installation",
    "text": "20.3 kubectl installation\nAfter creating a cluster, you can use kubectl to interact with it by using the configuration file generated by kind. We follow the official installation tutorial to install kubectl.\n\nChange directory\n\ncd /home/ubuntu\n\nDownload the latest release with the command:\n\nsudo curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n\nInstall kubectl\n\nsudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n\nTest to ensure the version you installed is up-to-date:\n\nkubectl version --client --output=yaml"
  },
  {
    "objectID": "k8s-setup.html#interacting-with-your-cluster",
    "href": "k8s-setup.html#interacting-with-your-cluster",
    "title": "20¬† Kubernetes setup",
    "section": "20.4 Interacting With Your Cluster",
    "text": "20.4 Interacting With Your Cluster\n\n\nCheck that kubectl is properly configured by getting the cluster state:\n\nsudo kubectl cluster-info\n\nList any existing Pods\n\nsudo kubectl get pods\nThis should output: ‚ÄúNo resources found in default namespace.‚Äù"
  },
  {
    "objectID": "k8s-setup.html#prepare-environment",
    "href": "k8s-setup.html#prepare-environment",
    "title": "20¬† Kubernetes setup",
    "section": "20.5 Prepare environment",
    "text": "20.5 Prepare environment\nIn the following steps, we will use some of Nigel Poulton‚Äôs examples from ‚ÄúThe Kubernetes Book (2022)‚Äù. Therefore, we will clone his GitHub-repo on our virtual machine.\n\nChange directory to mnt/vdb\n\ncd /mnt/vdb\n\nMake a new directory:\n\nmkdir github\n\nChange into the directory:\n\ncd github\n\nClone this GitHub-repo into the directory:\n\ngit clone https://github.com/nigelpoulton/TheK8sBook.git"
  },
  {
    "objectID": "k8s-pod-hello.html#what-is-a-pod",
    "href": "k8s-pod-hello.html#what-is-a-pod",
    "title": "21¬† Deploying Pods from a manifest file",
    "section": "21.1 What is a Pod?",
    "text": "21.1 What is a Pod?\nIn Kubernetes, the basic building block is a Pod. A Pod can contain one or more ‚Äòcontainers‚Äô (usually Docker containers), which are like mini-programs, and all of these get sent to a single computer in the group (or ‚Äòcluster‚Äô) at the same time.\nWe use special instruction files (YAML manifest files) to tell Kubernetes how and what to deploy, and it‚Äôs common to use tools called ‚ÄòDeployments‚Äô and ‚ÄòDaemonSets‚Äô to manage these Pods.\nIf a Pod is set up without using a controller, like a Deployment or DaemonSet, it‚Äôs known as a ‚Äòstatic‚Äô Pod. To set up these Pods, we use a command kubectl apply to send the instruction files to the Kubernetes control center (the ‚ÄòAPI server‚Äô), and then Kubernetes decides which computer in the cluster will run the Pod.\nA special program on the chosen computer, called the ‚Äòkubelet daemon‚Äô, takes care of starting the Pod and keeping an eye on it, and tries to fix problems locally. But if the computer running a static Pod has a problem and stops working, the Pod won‚Äôt be automatically replaced."
  },
  {
    "objectID": "k8s-pod-hello.html#deploying-pods-from-a-manifest-file",
    "href": "k8s-pod-hello.html#deploying-pods-from-a-manifest-file",
    "title": "21¬† Deploying Pods from a manifest file",
    "section": "21.2 Deploying Pods from a manifest file",
    "text": "21.2 Deploying Pods from a manifest file\n\nChange directory into the pods folder:\n\ncd /mnt/vdb/github/TheK8sBook/pods\n\nCreate your Pod with the manifest file pod.yml:\n\nsudo kubectl apply -f pod.yml\nHere is the content of pod.yml:\napiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-pod\n  labels:\n    zone: prod\n    version: v1\nspec:\n  containers:\n  - name: hello-ctr\n    image: nigelpoulton/k8sbook:1.0\n    ports:\n    - containerPort: 8080\nIn essence, this YAML file creates a Pod named hello-pod with a single container called hello-ctr. The container is created from the nigelpoulton/k8sbook:1.0 Docker image and exposes port 8080 for network communication. The Pod is labelled with zone: prod and version: v1 to help manage and organize it better.\nHere‚Äôs a breakdown of what each part of the YAML file means:\napiVersion: v1: This indicates the version of the Kubernetes API you‚Äôre using to create this object.\nkind: Pod: This line indicates that the type of the Kubernetes object you‚Äôre creating is a Pod.\nmetadata: This section provides data that helps uniquely identify the Pod.\n`name:` hello-pod: This is the name of the Pod.\n`labels:` These are key-value pairs that are used to organize and categorize Pods. Here, `zone`: prod and `version`: v1 are used as labels.\nspec: This section defines the desired state for this Pod, meaning what containers should be running.\n`containers:` This is a list of containers that should be launched inside this Pod.\n`name: hello-ctr`: This is the name of the container.\n`image: nigelpoulton/k8sbook:1.0`: This indicates the Docker image to be used for this container. The image is taken from a public Docker image repository.\n`ports:` This lists the network ports the container should expose. containerPort: 8080 means that the container is listening on port 8080."
  },
  {
    "objectID": "k8s-pod-hello.html#check-the-status-of-pods",
    "href": "k8s-pod-hello.html#check-the-status-of-pods",
    "title": "21¬† Deploying Pods from a manifest file",
    "section": "21.3 Check the status of Pods",
    "text": "21.3 Check the status of Pods\n\nShow status of your Pod with:\n\nsudo kubectl get Pods\nThis sould output something like:\nNAME        READY   STATUS    RESTARTS   AGE\nhello-pod   1/1     Running   0          2m48s\nThe Pod is running on a node and is being monitored by the local kubelet process.\n\nTo get a more detailed overview use:\n\nsudo kubectl get pods -o yaml\n\nAnother option is:\n\nsudo kubectl describe pods hello-pod"
  },
  {
    "objectID": "k8s-pod-hello.html#running-commands-in-pods",
    "href": "k8s-pod-hello.html#running-commands-in-pods",
    "title": "21¬† Deploying Pods from a manifest file",
    "section": "21.4 Running commands in Pods",
    "text": "21.4 Running commands in Pods\nNext, we will execute a command from inside the Pod.\n\nUse kubectl exec -it to open an interactive session:\n\nsudo kubectl exec -it hello-pod -- sh\n\nFor example, let‚Äôs show the Pod hostname inside the interactive session:\n\nenv | grep HOSTNAME\nThe hostname of the container is set to the Pod‚Äôs name. Note that you should always set Pod names as valid DNS names (a-z and 0-9, the minus sign and the period sign).\n\nType exit to get back to the terminal\n\nexit\n\nLet‚Äôs delete this Pod:\n\nsudo kubectl delete pod hello-pod"
  },
  {
    "objectID": "k8s-pod-multi-container.html#prepare-environment",
    "href": "k8s-pod-multi-container.html#prepare-environment",
    "title": "22¬† Multi-container Pod",
    "section": "22.1 Prepare environment",
    "text": "22.1 Prepare environment\nFirst, we need to make some preparations in GitHub:\n\nLog in to your GitHub account.\nFork the following GitHub repo (this is so you can make a change to the repo and see those changes reflected by the app) to your GitHub-Account (keep the name as suggested by GitHub):\n\nhttps://github.com/nigelpoulton/ps-sidecar/fork\nNow, in your virtual machine:\n\nOpen this folder in VS Code: /mnt/vdb/github/TheK8sBook/pods/\nOpen the file sidecarpod-cloud.yml\nUpdate the GIT_SYNC_REPO value to reflect your forked repo and save your changes (replace https://github.com/nigelpoulton/ps-sidecar.git with your URl. In my case https://github.com/kirenz/ps-sidecar.git )"
  },
  {
    "objectID": "k8s-pod-multi-container.html#create-multi-container-pod",
    "href": "k8s-pod-multi-container.html#create-multi-container-pod",
    "title": "22¬† Multi-container Pod",
    "section": "22.2 Create multi-container Pod",
    "text": "22.2 Create multi-container Pod\n\nChange directory into the pods folder:\n\ncd /mnt/vdb/github/TheK8sBook/pods\n\nThis command will deploy the multi-container Pod as well as a Service object you can use to connect to the app.\n\nsudo kubectl apply -f sidecar-cloud.yml\nThis should output\npod/git-sync created\nservice/svc-sidecar created\n\nExplanation of sidecar-cloud.yml:\nIn summary, the YAML file sidecar-cloud.yml creates a Pod named git-sync with two containers. The first container serves content using nginx and the second container syncs a git repository into a shared volume. A Service named svc-sidecar is also created to expose the nginx server to the internet via a load balancer on port 80.\nThe file is defining a Pod and a Service:\nPod Configuration\napiVersion: v1: This indicates the version of the Kubernetes API you‚Äôre using to create this object.\nkind: Pod: This line indicates that the type of the Kubernetes object you‚Äôre creating is a Pod.\nmetadata: This section provides data that helps uniquely identify the Pod.\n`name: git-sync`: This is the name of the Pod.\n`labels`: These are key-value pairs that are used to organize and categorize Pods. Here, `app: sidecar` is used as a label.\nspec: This section defines the desired state for this Pod, meaning what containers should be running.\n`containers`: This is a list of two containers that should be launched inside this Pod.\n\nThe first container `ctr-web` is based on the nginx image and mounts a volume named html at `/usr/share/nginx/`.\n\nThe second container `ctr-sync` is based on the `k8s.gcr.io/git-sync:v3.1.6` image. This container mounts the same html volume, but at `/tmp/git`. This container also has several environment variables defined to clone a git repository into the mounted volume.\n\n`volumes`: This is a list of storage volumes that are available to the containers running in the Pod. Here, an emptyDir volume named html is created. This type of volume is initially empty and containers in the pod can read from and write to the same volume.\nService Configuration\napiVersion: v1: This indicates the version of the Kubernetes API you‚Äôre using to create this object.\nkind: Service: This line indicates that the type of the Kubernetes object you‚Äôre creating is a Service.\nmetadata: This section provides data that helps uniquely identify the Service.\n`name: svc-sidecar`: This is the name of the Service.\nspec: This section defines the desired state for this Service.\n`selector`: This is used to find the Pods that the Service should manage traffic for. Here, it selects the Pod with the label `app: sidecar`.\n\n`ports`: This lists the network port the Service should expose. port: 80 means that the Service is exposed on port 80.\n\n`type: LoadBalancer`: This means that the Service will be exposed through a cloud provider's load balancer.\n\n\nMonitor the status of your pods with:\n\nsudo kubectl get pods\n\nUse this command to get the connection details:\n\nsudo kubectl get svc\n\nTo get more information, run:\n\nsudo kubectl describe services svc-sidecar\nThis sould output something like:\nNAME          TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE\nkubernetes    ClusterIP      10.96.0.1      &lt;none&gt;        443/TCP        172m\nsvc-sidecar   LoadBalancer   10.96.62.142   &lt;pending&gt;     80:30408/TCP   15m\nIn this example, the external IP address (which we need to take a look at our website) is pending since Kubernetes does not offer an implementation of network load balancers (Services of type LoadBalancer) for clusters like ours. This means if you‚Äôre not running on a supported IaaS platform (GCP, AWS, Azure‚Ä¶), LoadBalancers will remain in the ‚Äúpending‚Äù state indefinitely when created. Therefore, we need to use a solution provided by MetalLB, which is described in the next section."
  },
  {
    "objectID": "k8s-pod-multi-container.html#create-network-load-balancer-with-metallb",
    "href": "k8s-pod-multi-container.html#create-network-load-balancer-with-metallb",
    "title": "22¬† Multi-container Pod",
    "section": "22.3 Create Network load-balancer with MetalLB",
    "text": "22.3 Create Network load-balancer with MetalLB\nMetalLB hooks into your Kubernetes cluster, and provides a network load-balancer implementation. In short, it allows you to create Kubernetes services of type LoadBalancer in clusters that don‚Äôt run on a cloud provider, and thus cannot simply hook into paid products to provide load balancers.\nThe following steps cover how to get service of type LoadBalancer working in a kind cluster using Metallb (review this tutorial from kind for more information).\n\nInstalling MetalLB using default manifests:\n\nsudo kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.7/config/manifests/metallb-native.yaml\n\nRun the following command (this ensures that Kubernetes waits until the MetalLB pods (controller and speakers) are ready):\n\nsudo kubectl wait --namespace metallb-system \\\n                --for=condition=ready pod \\\n                --selector=app=metallb \\\n                --timeout=90s\n\n\nWe need to provide MetalLB a range of IP addresses it controls. We want this range to be on the docker kind network:\n\nsudo docker network inspect -f '{{.IPAM.Config}}' kind\n\nThis will output some IP addresses like the following:\n\n[{172.20.0.0/16  172.20.0.1 map[]} {fc00:f853:ccd:e793::/64   map[]}]\nThe output will contain a CIDR such as 172.20.0.0/16. We want our loadbalancer IP range to come from this subclass. We can configure MetalLB, in my case, to use 172.20.255.200 to 172.20.255.250 (see YAML file below).\n\nNext, create a new YAML-file called metal-config.yaml\n\ntouch metal-config.yaml\n\nIn VS Code, open metal-config.yaml and insert the content below (change the IP addresses accordingly):\n\napiVersion: metallb.io/v1beta1\nkind: IPAddressPool\nmetadata:\n  name: example\n  namespace: metallb-system\nspec:\n  addresses:\n  - 172.20.255.200-172.20.255.250\n---\napiVersion: metallb.io/v1beta1\nkind: L2Advertisement\nmetadata:\n  name: empty\n  namespace: metallb-system\nSave the file.\n\nApply the contents\n\nsudo kubectl apply -f metal-config.yaml \nThis should output:\nipaddresspool.metallb.io/example created\nl2advertisement.metallb.io/empty created\nThat‚Äôs it. Now we can obtain the external IP."
  },
  {
    "objectID": "k8s-pod-multi-container.html#obtain-external-ip",
    "href": "k8s-pod-multi-container.html#obtain-external-ip",
    "title": "22¬† Multi-container Pod",
    "section": "22.4 Obtain External-IP",
    "text": "22.4 Obtain External-IP\n\nShow external-IP\n\nsudo kubectl get svc \nThe output should be similar to (your IP-address will be different):\nNAME          TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)        AGE\nkubernetes    ClusterIP      10.96.0.1      &lt;none&gt;           443/TCP        4h23m\nsvc-sidecar   LoadBalancer   10.96.62.142   172.20.255.200   80:30408/TCP   106m\n\n\nTo make a quick test, open the site in yout terminal (change the IP accordingly)\n\nsudo curl http://172.20.255.200:80 \nThe result should display some HTML code including the content of your forked repo:\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;NGINX&lt;/title&gt;\n&lt;style&gt;\n    body {\n        width: 35em;\n        margin: 0 auto;\n        font-family: Tahoma, Verdana, Arial, sans-serif;\n    }\n&lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;This is version 1.0&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;"
  },
  {
    "objectID": "k8s-pod-multi-container.html#port-forwarding",
    "href": "k8s-pod-multi-container.html#port-forwarding",
    "title": "22¬† Multi-container Pod",
    "section": "22.5 Port forwarding",
    "text": "22.5 Port forwarding\nTo be able to access a port on the remote machine that may not be publicly exposed, you need to establish a connection or a tunnel between a port on your local machine and the server.\nTo browse to the web app on your local machine, you can leverage the VS Code feature called Port Forwarding\n\nOpen the PORTS view in VS Code (next to the integrated TERMINAL).\nClick on ‚ÄúAdd Port‚Äù and enter your new port (the IP address you obtained). It should look something like: 172.20.255.200:80\nOpen the browser symbol to view the page in your browser.\n\nThe web page should display the content of your forked repo ‚Äì ‚ÄúThis is version 1.0‚Äù"
  },
  {
    "objectID": "k8s-pod-multi-container.html#make-changes-in-github",
    "href": "k8s-pod-multi-container.html#make-changes-in-github",
    "title": "22¬† Multi-container Pod",
    "section": "22.6 Make changes in GitHub",
    "text": "22.6 Make changes in GitHub\nGo to GitHub:\n\nOpen and edit the file index.html in your forked GitHub-repo ps-sidecar and make a change to the h1 line (e.g.¬†call it ‚ÄúThis is version 2.0‚Äù).\nCommit the changes and open the browser tab from before (with the ‚ÄúThis is version 1.0‚Äù web page).\nRefresh your browser. The update should be reflected almost immediately in the app: ‚ÄúThis is version 2.0‚Äù\n\nCongratulations! The sidecar container has successfully watched a GitHub repo and sync‚Äôd changes to your app.\nFeel free to run the sudo kubectl get pods and sudo kubectl describe pod commands to see how multi-container Pods appear in the outputs."
  },
  {
    "objectID": "k8s-pod-multi-container.html#delete-pod",
    "href": "k8s-pod-multi-container.html#delete-pod",
    "title": "22¬† Multi-container Pod",
    "section": "22.7 Delete Pod",
    "text": "22.7 Delete Pod\n\nIf you are done, delete the Pod:\n\nsudo kubectl delete pod git-sync"
  }
]